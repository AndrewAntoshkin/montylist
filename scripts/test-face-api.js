#!/usr/bin/env node
/**
 * Ð¢ÐµÑÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð¾ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ @vladmandic/face-api Ð½Ð° Node.js 22 + Apple Silicon
 */

const fs = require('fs');
const path = require('path');

async function testFaceApi() {
  console.log('\nðŸ§ª TESTING @vladmandic/face-api COMPATIBILITY\n');
  console.log(`   Node.js: ${process.version}`);
  console.log(`   Platform: ${process.platform}`);
  console.log(`   Arch: ${process.arch}\n`);
  
  const results = {
    import: false,
    canvas: false,
    tfjs: false,
    modelsLoad: false,
    faceDetection: false,
  };
  
  let faceapi;
  
  // Ð¢ÐµÑÑ‚ 1: Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ @vladmandic/face-api
  console.log('ðŸ“¦ Test 1: Import @vladmandic/face-api...');
  try {
    faceapi = require('@vladmandic/face-api');
    console.log('   âœ… @vladmandic/face-api imported successfully');
    console.log(`   ðŸ“¦ Version: ${faceapi.version || 'unknown'}`);
    results.import = true;
  } catch (err) {
    console.log(`   âŒ FAILED: ${err.message}`);
    return results;
  }
  
  // Ð¢ÐµÑÑ‚ 2: Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ canvas
  console.log('\nðŸ“¦ Test 2: Import canvas...');
  try {
    const { Canvas, Image, ImageData } = require('canvas');
    console.log('   âœ… canvas imported successfully');
    
    // Monkey-patch Ð´Ð»Ñ faceapi
    faceapi.env.monkeyPatch({ Canvas, Image, ImageData });
    console.log('   âœ… canvas patched to face-api');
    results.canvas = true;
  } catch (err) {
    console.log(`   âŒ FAILED: ${err.message}`);
  }
  
  // Ð¢ÐµÑÑ‚ 3: ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° TensorFlow.js
  console.log('\nðŸ“¦ Test 3: Check TensorFlow.js backend...');
  try {
    const tf = faceapi.tf;
    console.log(`   âœ… TensorFlow.js version: ${tf.version.tfjs}`);
    console.log(`   âœ… Backend: ${tf.getBackend() || 'not set yet'}`);
    results.tfjs = true;
  } catch (err) {
    console.log(`   âŒ FAILED: ${err.message}`);
  }
  
  // Ð¢ÐµÑÑ‚ 4: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
  console.log('\nðŸ“¦ Test 4: Load face-api models...');
  try {
    const modelPath = path.join(__dirname, '..', 'models', 'face-api');
    
    if (fs.existsSync(modelPath)) {
      console.log(`   ðŸ“ Models found at: ${modelPath}`);
      
      await faceapi.nets.tinyFaceDetector.loadFromDisk(modelPath);
      console.log('   âœ… TinyFaceDetector loaded');
      
      await faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath);
      console.log('   âœ… FaceLandmark68Net loaded');
      
      await faceapi.nets.faceRecognitionNet.loadFromDisk(modelPath);
      console.log('   âœ… FaceRecognitionNet loaded');
      
      results.modelsLoad = true;
    } else {
      console.log(`   âš ï¸  Models not found at ${modelPath}`);
      console.log('   ðŸ’¡ Downloading models...');
      
      // Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ
      fs.mkdirSync(modelPath, { recursive: true });
      
      // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ð¹ URL Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
      const modelUrl = 'https://vladmandic.github.io/face-api/model/';
      await faceapi.nets.tinyFaceDetector.loadFromUri(modelUrl);
      console.log('   âœ… TinyFaceDetector downloaded');
      
      await faceapi.nets.faceLandmark68Net.loadFromUri(modelUrl);
      console.log('   âœ… FaceLandmark68Net downloaded');
      
      await faceapi.nets.faceRecognitionNet.loadFromUri(modelUrl);
      console.log('   âœ… FaceRecognitionNet downloaded');
      
      results.modelsLoad = true;
    }
  } catch (err) {
    console.log(`   âŒ FAILED: ${err.message}`);
    console.log(err.stack);
  }
  
  // Ð¢ÐµÑÑ‚ 5: Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð»Ð¸Ñ†
  console.log('\nðŸ“¦ Test 5: Face detection on test image...');
  try {
    const { createCanvas } = require('canvas');
    
    // Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (640x480 Ð±ÐµÐ»Ñ‹Ð¹ Ñ„Ð¾Ð½)
    const canvas = createCanvas(640, 480);
    const ctx = canvas.getContext('2d');
    ctx.fillStyle = 'white';
    ctx.fillRect(0, 0, 640, 480);
    
    // Ð Ð¸ÑÑƒÐµÐ¼ Ð¾Ð²Ð°Ð» "Ð»Ð¸Ñ†Ð°" Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð°
    ctx.beginPath();
    ctx.fillStyle = '#f5d0c5'; // Ð¢ÐµÐ»ÐµÑÐ½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚
    ctx.ellipse(320, 200, 80, 100, 0, 0, 2 * Math.PI);
    ctx.fill();
    
    // Ð“Ð»Ð°Ð·Ð°
    ctx.beginPath();
    ctx.fillStyle = 'black';
    ctx.arc(290, 180, 10, 0, 2 * Math.PI);
    ctx.arc(350, 180, 10, 0, 2 * Math.PI);
    ctx.fill();
    
    // Ð Ð¾Ñ‚
    ctx.beginPath();
    ctx.strokeStyle = 'red';
    ctx.lineWidth = 3;
    ctx.arc(320, 230, 30, 0.2 * Math.PI, 0.8 * Math.PI);
    ctx.stroke();
    
    console.log('   ðŸ“¸ Test image created (640x480 with simple face)');
    
    // ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð´ÐµÑ‚ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
    const detections = await faceapi.detectAllFaces(
      canvas, 
      new faceapi.TinyFaceDetectorOptions({ inputSize: 416, scoreThreshold: 0.3 })
    );
    
    console.log(`   âœ… Detection successful! Found ${detections.length} faces`);
    console.log('   âœ… Face detection pipeline works!');
    results.faceDetection = true;
    
  } catch (err) {
    console.log(`   âŒ FAILED: ${err.message}`);
    console.log(err.stack);
  }
  
  // Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚
  console.log('\n' + 'â•'.repeat(60));
  console.log('ðŸ“Š RESULTS SUMMARY:');
  console.log('â•'.repeat(60));
  
  for (const [test, passed] of Object.entries(results)) {
    console.log(`   ${passed ? 'âœ…' : 'âŒ'} ${test}: ${passed ? 'PASSED' : 'FAILED'}`);
  }
  
  const allPassed = Object.values(results).every(v => v);
  console.log('\n' + (allPassed 
    ? 'ðŸŽ‰ ALL TESTS PASSED - Face Recognition is fully functional!' 
    : 'âš ï¸  SOME TESTS FAILED - see details above'));
  
  return results;
}

testFaceApi().then(results => {
  console.log('\n');
  process.exit(Object.values(results).every(v => v) ? 0 : 1);
}).catch(err => {
  console.error('Fatal error:', err);
  process.exit(1);
});
