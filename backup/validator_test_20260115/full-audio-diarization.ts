/**
 * Full Audio Diarization Module
 * 
 * ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ’Ğ¡Ğ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ¸Ğ»ÑŒĞ¼Ğ° Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼ Ğº AssemblyAI
 * Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Speaker ID Ğ½Ğ° Ğ²ĞµÑÑŒ Ñ„Ğ¸Ğ»ÑŒĞ¼.
 * 
 * Ğ¤Ğ»Ğ¾Ñƒ:
 * 1. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸Ğ· Ğ²Ğ¸Ğ´ĞµĞ¾ (FFmpeg)
 * 2. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ² Supabase Storage
 * 3. ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² AssemblyAI (Ğ¾Ğ´Ğ¸Ğ½ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ)
 * 4. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ words Ñ Speaker ID (A, B, C...)
 * 5. ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ: Speaker â†’ ĞŸĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ (Ğ¸Ğ· Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… ÑÑ†ĞµĞ½ Ñ Gemini)
 * 6. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Ñ‡Ğ°Ğ½ĞºĞ°Ñ…
 */

import { AssemblyAI, TranscriptWord } from 'assemblyai';
import { exec } from 'child_process';
import { promisify } from 'util';
import { existsSync, unlinkSync, statSync } from 'fs';
import path from 'path';

const execAsync = promisify(exec);

/**
 * Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
 */
export interface FullDiarizationResult {
  words: DiarizedWordFull[];
  speakers: string[];
  speakerCount: number;
  totalDuration: number;  // ÑĞµĞºÑƒĞ½Ğ´Ñ‹
  text: string;
}

/**
 * Ğ¡Ğ»Ğ¾Ğ²Ğ¾ Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğµ (Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)
 */
export interface DiarizedWordFull {
  word: string;
  start: number;      // Ğ¼Ğ¸Ğ»Ğ»Ğ¸ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¾Ñ‚ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ñ„Ğ¸Ğ»ÑŒĞ¼Ğ°
  end: number;        // Ğ¼Ğ¸Ğ»Ğ»Ğ¸ÑĞµĞºÑƒĞ½Ğ´Ñ‹
  speaker: string;    // A, B, C...
  confidence: number;
}

/**
 * ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Speaker â†’ Character
 */
export interface SpeakerCharacterMapping {
  speakerId: string;
  characterName: string;
  confidence: number;
  calibrationTimecode: string;
}

/**
 * ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾
 */
export interface VideoDiarizationData {
  videoId: string;
  result: FullDiarizationResult;
  speakerMapping: SpeakerCharacterMapping[];
  createdAt: number;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ĞĞ¡ĞĞĞ’ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸Ğ· Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
 */
export async function extractFullAudio(
  videoPath: string,
  outputPath: string
): Promise<string> {
  console.log(`ğŸµ Extracting full audio from video...`);
  console.log(`   Input: ${videoPath}`);
  console.log(`   Output: ${outputPath}`);
  
  // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
  if (!existsSync(videoPath)) {
    throw new Error(`Video file not found: ${videoPath}`);
  }
  
  const videoSize = statSync(videoPath).size / (1024 * 1024);
  console.log(`   Video size: ${videoSize.toFixed(1)} MB`);
  
  // FFmpeg: Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² MP3
  const ffmpegCmd = `ffmpeg -y -i "${videoPath}" -vn -acodec libmp3lame -ab 128k -ar 44100 "${outputPath}"`;
  
  try {
    console.log(`   Running FFmpeg...`);
    const { stderr } = await execAsync(ffmpegCmd, { maxBuffer: 50 * 1024 * 1024 });
    
    if (!existsSync(outputPath)) {
      throw new Error('FFmpeg did not create output file');
    }
    
    const audioSize = statSync(outputPath).size / (1024 * 1024);
    console.log(`   âœ… Audio extracted: ${audioSize.toFixed(1)} MB`);
    
    return outputPath;
  } catch (error) {
    console.error(`   âŒ FFmpeg error:`, error);
    throw error;
  }
}

/**
 * Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· AssemblyAI
 * 
 * @param audioUrl - URL Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹)
 * @param language - ÑĞ·Ñ‹Ğº (default: ru)
 * @param speakerHints - Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ¸ Ğ¸Ğ¼Ñ‘Ğ½ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹ Ğ´Ğ»Ñ word boost
 * @param maxSpeakers - Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
 */
export async function performFullDiarization(
  audioUrl: string,
  language: string = 'ru',
  speakerHints: string[] = [],
  maxSpeakers: number = 10
): Promise<FullDiarizationResult> {
  const apiKey = process.env.ASSEMBLYAI_API_KEY;
  if (!apiKey) {
    throw new Error('ASSEMBLYAI_API_KEY not set');
  }
  
  const client = new AssemblyAI({ apiKey });
  
  console.log(`\nğŸ¤ FULL DIARIZATION: Starting AssemblyAI transcription...`);
  console.log(`   URL: ${audioUrl.substring(0, 80)}...`);
  console.log(`   Language: ${language}`);
  console.log(`   Max speakers: ${maxSpeakers}`);
  console.log(`   Word boost: ${speakerHints.slice(0, 5).join(', ')}...`);
  console.log(`   â³ This may take several minutes for long videos...`);
  
  const startTime = Date.now();
  
  try {
    const transcript = await client.transcripts.transcribe({
      audio_url: audioUrl,
      speaker_labels: true,
      language_code: language,
      word_boost: speakerHints.slice(0, 20),
      boost_param: 'high',
      speakers_expected: Math.min(maxSpeakers, 10),
      punctuate: true,
      format_text: true,
    });
    
    if (transcript.status === 'error') {
      throw new Error(`AssemblyAI error: ${transcript.error}`);
    }
    
    const duration = (Date.now() - startTime) / 1000;
    console.log(`   âœ… Transcription completed in ${duration.toFixed(1)}s`);
    
    // ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ°
    const words: DiarizedWordFull[] = (transcript.words || []).map((w: TranscriptWord) => ({
      word: w.text || '',
      start: w.start,
      end: w.end,
      speaker: w.speaker || 'A',
      confidence: w.confidence,
    }));
    
    // Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
    const speakersSet = new Set<string>();
    for (const w of words) {
      speakersSet.add(w.speaker);
    }
    const speakers = Array.from(speakersSet).sort();
    
    const totalDuration = (transcript.audio_duration || 0) / 1000;
    
    console.log(`\nğŸ“Š DIARIZATION RESULTS:`);
    console.log(`   Total words: ${words.length}`);
    console.log(`   Speakers found: ${speakers.length} (${speakers.join(', ')})`);
    console.log(`   Audio duration: ${(totalDuration / 60).toFixed(1)} min`);
    console.log(`   Text length: ${(transcript.text || '').length} chars`);
    
    return {
      words,
      speakers,
      speakerCount: speakers.length,
      totalDuration,
      text: transcript.text || '',
    };
    
  } catch (error) {
    console.error(`   âŒ AssemblyAI error:`, error);
    throw error;
  }
}

/**
 * ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ»Ğ¾Ğ²Ğ° ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ² Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ
 */
export function getWordsForSpeakerInRange(
  words: DiarizedWordFull[],
  speaker: string,
  startMs: number,
  endMs: number
): DiarizedWordFull[] {
  return words.filter(w => 
    w.speaker === speaker &&
    w.start >= startMs &&
    w.end <= endMs
  );
}

/**
 * ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ²ÑĞµ ÑĞ»Ğ¾Ğ²Ğ° Ğ² Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ
 */
export function getWordsInTimeRange(
  words: DiarizedWordFull[],
  startMs: number,
  endMs: number
): DiarizedWordFull[] {
  return words.filter(w => w.start >= startMs && w.end <= endMs);
}

/**
 * ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ² Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ
 */
export function getDominantSpeaker(
  words: DiarizedWordFull[],
  startMs: number,
  endMs: number
): string | null {
  const rangeWords = getWordsInTimeRange(words, startMs, endMs);
  
  if (rangeWords.length === 0) return null;
  
  const speakerCounts: Record<string, number> = {};
  for (const w of rangeWords) {
    speakerCounts[w.speaker] = (speakerCounts[w.speaker] || 0) + 1;
  }
  
  const sorted = Object.entries(speakerCounts).sort((a, b) => b[1] - a[1]);
  return sorted[0]?.[0] || null;
}

/**
 * Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ğ»Ğ°Ğ½Ğµ
 */
export function formatWordsForDisplay(
  words: DiarizedWordFull[],
  startMs: number,
  endMs: number,
  speakerMapping: Record<string, string>
): string {
  const rangeWords = getWordsInTimeRange(words, startMs, endMs);
  
  if (rangeWords.length === 0) return '';
  
  // Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°Ğ¼
  const speakerTexts: Record<string, string[]> = {};
  let currentSpeaker = '';
  
  for (const w of rangeWords) {
    const speaker = speakerMapping[w.speaker] || w.speaker;
    if (speaker !== currentSpeaker) {
      currentSpeaker = speaker;
      if (!speakerTexts[speaker]) {
        speakerTexts[speaker] = [];
      }
    }
    speakerTexts[currentSpeaker].push(w.word);
  }
  
  // Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼
  const lines: string[] = [];
  for (const [speaker, words] of Object.entries(speakerTexts)) {
    lines.push(`${speaker}\n${words.join(' ')}`);
  }
  
  return lines.join('\n');
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ĞšĞĞ›Ğ˜Ğ‘Ğ ĞĞ’ĞšĞ Ğ¡ĞŸĞ˜ĞšĞ•Ğ ĞĞ’
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ğ’ĞĞ Ğ˜ĞĞĞ¢Ğ« Ğ˜ĞœĞĞ Ğ”Ğ›Ğ¯ Ğ¢ĞĞ§ĞĞĞ™ ĞšĞĞ›Ğ˜Ğ‘Ğ ĞĞ’ĞšĞ˜
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const NAME_VARIANTS: Record<string, string[]> = {
  'Ğ¢ĞĞ¢Ğ¬Ğ¯ĞĞ': ['Ğ¢ĞĞĞ¯', 'Ğ¢ĞĞĞ¬ĞšĞ', 'Ğ¢ĞĞĞ®Ğ¨Ğ', 'Ğ¢ĞĞĞ®Ğ¥Ğ', 'Ğ¢ĞĞĞ¬'],
  'Ğ¢ĞĞœĞĞ Ğ': ['Ğ¢ĞĞœĞ', 'Ğ¢ĞĞœĞšĞ', 'Ğ¢ĞĞœĞĞ§ĞšĞ'],  // Ğ¢ĞĞœĞ â‰  Ğ¢ĞĞĞ¯!
  'Ğ“ĞĞ›Ğ˜ĞĞ': ['Ğ“ĞĞ›Ğ¯', 'Ğ“ĞĞ›ĞĞ§ĞšĞ', 'Ğ“ĞĞ›Ğ®Ğ¡Ğ¯', 'Ğ“ĞĞ›Ğ¬ĞšĞ'],
  'Ğ¡Ğ’Ğ•Ğ¢Ğ›ĞĞĞ': ['Ğ¡Ğ’Ğ•Ğ¢Ğ', 'Ğ¡Ğ’Ğ•Ğ¢Ğ˜Ğš', 'Ğ¡Ğ’Ğ•Ğ¢ĞĞ§ĞšĞ', 'Ğ¡Ğ’Ğ•Ğ¢ĞšĞ'],
  'Ğ•Ğ›Ğ•ĞĞ': ['Ğ›Ğ•ĞĞ', 'Ğ›Ğ•ĞĞĞ§ĞšĞ', 'Ğ›Ğ•ĞĞšĞ'],
  'ĞĞĞ¢ĞĞ›Ğ¬Ğ¯': ['ĞĞĞ¢ĞĞ¨Ğ', 'ĞĞĞ¢ĞĞ¨ĞšĞ', 'ĞĞĞ¢Ğ£Ğ›Ğ¯'],
  'Ğ’ĞĞ›Ğ•ĞĞ¢Ğ˜ĞĞ': ['Ğ’ĞĞ›Ğ¯', 'Ğ’ĞĞ›Ğ®Ğ¨Ğ', 'Ğ’ĞĞ›Ğ¬ĞšĞ'],
  'ĞĞ›Ğ•ĞšĞ¡ĞĞĞ”Ğ Ğ': ['Ğ¡ĞĞ¨Ğ', 'Ğ¨Ğ£Ğ Ğ', 'Ğ¨Ğ£Ğ ĞĞ§ĞšĞ'],
  'Ğ›Ğ®Ğ”ĞœĞ˜Ğ›Ğ': ['Ğ›Ğ®Ğ”Ğ', 'Ğ›Ğ®Ğ”ĞĞ¡Ğ¯', 'Ğ›Ğ®Ğ”ĞĞ§ĞšĞ', 'Ğ›Ğ®Ğ¡Ğ¯'],
  'ĞœĞĞ Ğ˜Ğ¯': ['ĞœĞĞ¨Ğ', 'ĞœĞĞ¨ĞšĞ', 'ĞœĞĞ Ğ£Ğ¡Ğ¯'],
  'Ğ•ĞšĞĞ¢Ğ•Ğ Ğ˜ĞĞ': ['ĞšĞĞ¢Ğ¯', 'ĞšĞĞ¢Ğ®Ğ¨Ğ', 'ĞšĞĞ¢Ğ¬ĞšĞ'],
  'ĞĞĞĞ': ['ĞĞĞ¯', 'ĞĞĞ®Ğ¢Ğ', 'ĞĞ®Ğ Ğ'],
  'Ğ˜Ğ Ğ˜ĞĞ': ['Ğ˜Ğ Ğ', 'Ğ˜Ğ ĞĞ§ĞšĞ', 'Ğ˜Ğ ĞšĞ'],
  'ĞĞ›Ğ¬Ğ“Ğ': ['ĞĞ›Ğ¯', 'ĞĞ›Ğ•Ğ§ĞšĞ', 'ĞĞ›Ğ¬ĞšĞ'],
  'Ğ’ĞĞ Ğ’ĞĞ Ğ': ['Ğ’ĞĞ Ğ¯', 'Ğ’ĞĞ Ğ¬ĞšĞ', 'Ğ’ĞĞ Ğ®Ğ¨Ğ'],
  'Ğ›ĞĞ Ğ˜Ğ¡Ğ': ['Ğ›ĞĞ Ğ', 'Ğ›ĞĞ Ğ˜Ğ¡ĞšĞ', 'Ğ›ĞĞ ĞšĞ'],
  'Ğ—Ğ˜ĞĞĞ˜Ğ”Ğ': ['Ğ—Ğ˜ĞĞ', 'Ğ—Ğ˜ĞĞšĞ', 'Ğ—Ğ˜ĞĞ£Ğ›Ğ¯'],
};

// ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³: Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ â†’ ĞºĞ°Ğ½Ğ¾Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¸Ğ¼Ñ
function buildVariantToCanonical(knownCharacters: string[]): Map<string, string> {
  const map = new Map<string, string>();
  
  for (const char of knownCharacters) {
    map.set(char, char);
    
    // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹
    const variants = NAME_VARIANTS[char];
    if (variants) {
      for (const v of variants) {
        // Ğ•ÑĞ»Ğ¸ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¼ â€” Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ¼ Ğ½Ğ° ĞºĞ°Ğ½Ğ¾Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ
        if (!knownCharacters.includes(v)) {
          map.set(v, char);
        }
      }
    }
    
    // ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº: ĞµÑĞ»Ğ¸ char ÑÑ‚Ğ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ ĞºĞ¾Ğ³Ğ¾-Ñ‚Ğ¾
    for (const [canonical, variants] of Object.entries(NAME_VARIANTS)) {
      if (variants.includes(char) && knownCharacters.includes(canonical)) {
        map.set(char, canonical);
      }
    }
  }
  
  return map;
}

/**
 * ĞšĞ°Ğ»Ğ¸Ğ±Ñ€ÑƒĞµÑ‚ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Speaker â†’ Character Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ¸ Ğ¾Ñ‚ Gemini
 */
export function calibrateSpeakerMapping(
  diarizationResult: FullDiarizationResult,
  geminiScenes: Array<{
    start_timecode: string;
    end_timecode: string;
    description: string;
    dialogues: string;
  }>,
  knownCharacters: string[],
  timecodeToMs: (tc: string) => number,
  _fullDiarizationWords?: unknown,
  speakersToCalibrate?: string[]
): SpeakerCharacterMapping[] {
  const mappings: SpeakerCharacterMapping[] = [];
  const assignedSpeakers = new Set<string>();
  const assignedCharacters = new Set<string>();
  
  const variantToCanonical = buildVariantToCanonical(knownCharacters);
  const targetSpeakers = speakersToCalibrate || diarizationResult.speakers;
  
  console.log(`\nğŸ¯ CALIBRATING SPEAKERS â†’ CHARACTERS...`);
  console.log(`   Known characters: ${knownCharacters.length}`);
  console.log(`   Speakers to map: ${targetSpeakers.length}`);
  console.log(`   Scenes to analyze: ${geminiScenes.length}`);
  
  const findCharacterInText = (text: string): string | null => {
    const upper = text.toUpperCase();
    
    for (const char of knownCharacters) {
      if (upper.startsWith(char)) return char;
    }
    
    for (const [variant, canonical] of variantToCanonical) {
      if (upper.startsWith(variant) && !knownCharacters.includes(variant)) {
        return canonical;
      }
    }
    
    for (const char of knownCharacters) {
      const pattern = new RegExp(`\\b${char}\\b.{0,20}(Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚|Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµÑ‚|ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµÑ‚|ĞºÑ€Ğ¸Ñ‡Ğ¸Ñ‚)`, 'i');
      if (pattern.test(text)) return char;
    }
    
    for (const char of knownCharacters) {
      const linePattern = new RegExp(`^${char}\\s*$|\\n${char}\\s*\\n`, 'mi');
      if (linePattern.test(text)) return char;
    }
    
    return null;
  };
  
  for (const scene of geminiScenes) {
    const dialogueUpper = (scene.dialogues || '').toUpperCase();
    
    const startMs = timecodeToMs(scene.start_timecode);
    const endMs = timecodeToMs(scene.end_timecode);
    const wordsInScene = diarizationResult.words.filter(w => w.start < endMs && w.end > startMs);
    
    if (wordsInScene.length < 3) continue;
    
    let character: string | null = null;
    
    if (dialogueUpper && dialogueUpper !== 'ĞœĞ£Ğ—Ğ«ĞšĞ') {
      character = findCharacterInText(scene.dialogues);
    }
    
    if (!character && scene.description) {
      character = findCharacterInText(scene.description);
    }
    
    if (!character || assignedCharacters.has(character)) continue;
    
    const dominantSpeaker = getDominantSpeaker(diarizationResult.words, startMs, endMs);
    
    if (!dominantSpeaker || assignedSpeakers.has(dominantSpeaker)) continue;
    if (speakersToCalibrate && !speakersToCalibrate.includes(dominantSpeaker)) continue;
    
    const speakerWords = getWordsForSpeakerInRange(diarizationResult.words, dominantSpeaker, startMs, endMs);
    
    if (speakerWords.length < 3) continue;
    
    mappings.push({
      speakerId: dominantSpeaker,
      characterName: character,
      confidence: Math.min(speakerWords.length / 10, 1),
      calibrationTimecode: scene.start_timecode,
    });
    
    assignedSpeakers.add(dominantSpeaker);
    assignedCharacters.add(character);
    
    console.log(`   âœ… ${dominantSpeaker} â†’ ${character} (${speakerWords.length} words at ${scene.start_timecode})`);
    
    if (assignedSpeakers.size >= diarizationResult.speakers.length) {
      console.log(`   ğŸ‰ All speakers calibrated!`);
      break;
    }
  }
  
  console.log(`\nğŸ“Š Calibration complete: ${mappings.length}/${diarizationResult.speakers.length} speakers mapped`);
  
  return mappings;
}

/**
 * ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Record Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
 */
export function mappingToRecord(mappings: SpeakerCharacterMapping[]): Record<string, string> {
  const record: Record<string, string> = {};
  for (const m of mappings) {
    record[m.speakerId] = m.characterName;
  }
  return record;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ğ¡Ğ•Ğ Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export function serializeDiarization(data: VideoDiarizationData): string {
  return JSON.stringify(data);
}

export function deserializeDiarization(json: string): VideoDiarizationData | null {
  try {
    return JSON.parse(json) as VideoDiarizationData;
  } catch {
    return null;
  }
}

export function estimateCost(durationSeconds: number): number {
  return durationSeconds * 0.00025;
}
