import { createServiceRoleClient } from '@/lib/supabase/server';
import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';
import { parseGeminiResponse, parseAlternativeFormat } from '@/lib/parseGeminiResponse';
import { createChunkPrompt } from '@/lib/gemini-prompt';
import { validateTimecodeSequence } from '@/lib/timecode-validator';
import { timecodeToSeconds, secondsToTimecode } from '@/lib/video-chunking';
import { createPredictionWithRetry, pollPrediction } from '@/lib/replicate-helper';
import { getReplicatePool } from '@/lib/replicate-pool';

const MAX_PREDICTION_ATTEMPTS = 5; // –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 3 –¥–æ 5 –¥–ª—è –ª—É—á—à–µ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

// 5 minutes timeout per chunk
export const maxDuration = 300;
export const dynamic = 'force-dynamic';

export async function POST(request: NextRequest) {
  // Parse request body at the top level so we can access in catch block
  let videoId: string | undefined;
  let chunkIndex: number | undefined;
  
  try {
    const body = await request.json();
    videoId = body.videoId;
    chunkIndex = body.chunkIndex;
    const chunkStorageUrl = body.chunkStorageUrl;
    const startTimecode = body.startTimecode;
    const endTimecode = body.endTimecode;
    const filmMetadata = body.filmMetadata;

    if (!videoId || chunkIndex === undefined || !chunkStorageUrl) {
      return NextResponse.json(
        { error: 'Missing required fields: videoId, chunkIndex, chunkStorageUrl' },
        { status: 400 }
      );
    }

    console.log(`üé¨ Processing chunk ${chunkIndex} for video ${videoId}`);
    console.log(`üìπ Chunk: ${startTimecode} - ${endTimecode}`);
    console.log(`üìπ Chunk storage URL: ${chunkStorageUrl.substring(0, 100)}...`);
    
    // Test if URL is accessible
    try {
      const testResponse = await fetch(chunkStorageUrl, { method: 'HEAD' });
      console.log(`‚úÖ Chunk URL is accessible: ${testResponse.ok} (status: ${testResponse.status})`);
      if (!testResponse.ok) {
        console.warn(`‚ö†Ô∏è  Chunk URL returned non-200 status. This may cause issues with Gemini API.`);
      }
    } catch (testError) {
      console.error(`‚ùå Chunk URL is NOT accessible:`, testError);
    }

    const supabase = createServiceRoleClient();

    // Get video and chunk progress
    const { data: video, error: videoError } = await supabase
      .from('videos')
      .select('chunk_progress_json, user_id')
      .eq('id', videoId)
      .single();

    if (videoError || !video) {
      throw new Error('Video not found');
    }

    const chunkProgress = video.chunk_progress_json;
    if (!chunkProgress || !chunkProgress.chunks[chunkIndex]) {
      throw new Error('Chunk progress not found');
    }

    const totalChunks = chunkProgress.totalChunks || chunkProgress.chunks.length;

    // Update chunk status to processing
    chunkProgress.currentChunk = chunkIndex;
    chunkProgress.chunks[chunkIndex].status = 'processing';
    await supabase
      .from('videos')
      .update({ chunk_progress_json: chunkProgress })
      .eq('id', videoId);

    // Create prompt for this chunk
    const prompt = createChunkPrompt(chunkIndex, startTimecode, endTimecode, totalChunks);
    console.log(`üìù Generated prompt for chunk ${chunkIndex}`);

    // Get Replicate client from pool with least load (with rate limiting)
    const pool = getReplicatePool();
    const { client: replicate, keyIndex, release } = await pool.getLeastLoadedClient();

    // Start Replicate prediction with retries for transient errors (E6716)
    let completedPrediction: Awaited<ReturnType<typeof pollPrediction>> | null = null;

    try {
      for (let attempt = 1; attempt <= MAX_PREDICTION_ATTEMPTS; attempt++) {
        try {
          console.log(`üöÄ Starting Replicate prediction for chunk ${chunkIndex} using key #${keyIndex} (attempt ${attempt}/${MAX_PREDICTION_ATTEMPTS})...`);
          const prediction = await createPredictionWithRetry(
            replicate,
            'google/gemini-2.5-flash',
            {
              videos: [chunkStorageUrl], // Must be array for gemini-2.5-flash
              prompt,
            }
          );

          console.log(`‚è≥ Polling prediction ${prediction.id} for chunk ${chunkIndex}...`);
          completedPrediction = await pollPrediction(replicate, prediction.id);

          if (completedPrediction.status === 'failed') {
            throw new Error(`Replicate prediction failed: ${completedPrediction.error}`);
          }

          // Success, exit retry loop
          break;
        } catch (predictionError) {
          const message = predictionError instanceof Error ? predictionError.message : String(predictionError);
          const isE6716 = message.includes('E6716') || message.toLowerCase().includes('timeout starting prediction');
          const isE004 = message.includes('E004') || message.includes('Service is temporarily unavailable');
          const isTemporaryError = isE6716 || isE004;

          if (isTemporaryError && attempt < MAX_PREDICTION_ATTEMPTS) {
            // Exponential backoff –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫: 5s, 20s, 45s, 80s
            const exponentialBackoff = Math.pow(attempt, 2) * 5000;
            const backoffMs = Math.min(exponentialBackoff, 90000); // Max 90s
            const errorCode = isE004 ? 'E004' : 'E6716';
            console.warn(`‚ö†Ô∏è  Chunk ${chunkIndex} ${errorCode} (temporary error) on attempt ${attempt}. Retrying in ${backoffMs}ms (exponential backoff)...`);
            await new Promise(resolve => setTimeout(resolve, backoffMs));
            continue;
          }

          throw predictionError;
        }
      }
    } finally {
      // Always release the client back to the pool
      release();
    }

    if (!completedPrediction) {
      throw new Error('Replicate prediction did not complete after retries');
    }

    const output = completedPrediction.output;
    // Gemini 2.5 Flash returns output as array of strings, join them
    const aiResponse = Array.isArray(output) ? output.join('') : String(output);
    console.log(`‚úÖ Chunk ${chunkIndex} AI response received (${aiResponse.length} chars)`);
    
    // Check for empty response BEFORE parsing
    if (aiResponse.length === 0 || aiResponse.trim().length === 0) {
      console.error(`‚ùå EMPTY RESPONSE from Gemini for chunk ${chunkIndex}!`);
      console.error(`üîç Prediction ID: ${completedPrediction.id}`);
      console.error(`üîç Prediction status: ${completedPrediction.status}`);
      console.error(`üîç Raw output:`, JSON.stringify(output));
      
      // Mark chunk as failed and throw error to trigger retry at higher level
      chunkProgress.chunks[chunkIndex].status = 'failed';
      chunkProgress.chunks[chunkIndex].error = 'Empty response from AI';
      await supabase
        .from('videos')
        .update({ chunk_progress_json: chunkProgress })
        .eq('id', videoId);
      
      throw new Error(`Empty response from Gemini API for chunk ${chunkIndex}. This needs manual retry.`);
    }
    
    // Log first 500 chars of response for debugging
    console.log(`üìù AI Response preview:`, aiResponse.substring(0, 500));
    console.log(`üìù AI Response end:`, aiResponse.substring(Math.max(0, aiResponse.length - 500)));

    // Parse AI response
    let parsedScenes = parseGeminiResponse(aiResponse);
    
    if (parsedScenes.length === 0) {
      console.log(`‚ö†Ô∏è  Primary parser failed, trying alternative format for chunk ${chunkIndex}`);
      parsedScenes = parseAlternativeFormat(aiResponse);
    }

    if (parsedScenes.length === 0) {
      console.warn(`‚ö†Ô∏è  No scenes found in chunk ${chunkIndex} after trying all parsers`);
      console.warn(`üîç Full AI response:`, aiResponse);
    }

    console.log(`üìä Parsed ${parsedScenes.length} scenes from chunk ${chunkIndex}`);

    // NEW APPROACH: Gemini uses actual timecodes from video (embedded timecode)
    // No offset adjustment needed - just filter scenes within chunk range
    const chunkStartSeconds = timecodeToSeconds(startTimecode);
    const chunkEndSeconds = timecodeToSeconds(endTimecode);
    
    console.log(`üìä Chunk range: ${startTimecode} (${chunkStartSeconds}s) - ${endTimecode} (${chunkEndSeconds}s)`);
    
    // Filter scenes to only include those within this chunk's time range
    const validScenes = parsedScenes.filter(scene => {
      const sceneStartSeconds = timecodeToSeconds(scene.start_timecode);
      const sceneEndSeconds = timecodeToSeconds(scene.end_timecode);
      
      // Scene is valid if it starts within chunk range
      const isWithinRange = sceneStartSeconds >= chunkStartSeconds && sceneStartSeconds < chunkEndSeconds;
      
      if (!isWithinRange) {
        console.log(`‚ö†Ô∏è  Scene ${scene.start_timecode} - ${scene.end_timecode} is outside chunk range, filtering out`);
      }
      
      return isWithinRange;
    });
    
    if (validScenes.length < parsedScenes.length) {
      console.log(`‚ö†Ô∏è  Filtered out ${parsedScenes.length - validScenes.length} scenes outside chunk range (${chunkStartSeconds}s - ${chunkEndSeconds}s)`);
      console.log(`‚úÖ Kept ${validScenes.length} scenes within chunk range`);
      parsedScenes = validScenes;
    } else {
      console.log(`‚úÖ All ${parsedScenes.length} scenes are within chunk range`);
    }

    // Validate timecode sequence
    console.log('\nüîç Validating timecode sequence...');
    const validation = validateTimecodeSequence(parsedScenes);
    
    if (!validation.isValid) {
      console.warn(`‚ö†Ô∏è Timecode validation found ${validation.gaps.length} gaps and ${validation.overlaps.length} overlaps`);
      
      // Log first 5 issues for debugging
      validation.warnings.slice(0, 5).forEach(w => console.warn(w));
      if (validation.warnings.length > 5) {
        console.warn(`   ... and ${validation.warnings.length - 5} more warnings`);
      }
      
      // Calculate total lost time
      const totalLostFrames = validation.gaps.reduce((sum, g) => sum + g.gapDuration, 0);
      const totalLostSeconds = totalLostFrames / 24; // Assuming 24fps
      console.warn(`‚ö†Ô∏è Total lost time: ${totalLostFrames} frames (~${totalLostSeconds.toFixed(1)} seconds)`);
    } else {
      console.log('‚úÖ Timecode validation passed - no gaps or overlaps!');
    }

    // Get sheet ID from chunk progress
    const sheetId = chunkProgress.sheetId;
    if (!sheetId) {
      throw new Error('Sheet ID not found in chunk progress');
    }

    // Verify that the sheet actually exists in database (prevent foreign key errors)
    const { data: existingSheet, error: sheetCheckError } = await supabase
      .from('montage_sheets')
      .select('id')
      .eq('id', sheetId)
      .maybeSingle();

    if (sheetCheckError || !existingSheet) {
      console.error(`‚ùå Sheet ${sheetId} not found in database! Possibly deleted or from duplicate initialization.`);
      throw new Error(`Sheet ${sheetId} does not exist. Video may have been processed by duplicate request.`);
    }

    console.log(`‚úÖ Sheet ${sheetId} exists, proceeding with entry insertion`);

    // Determine the last assigned plan/order numbers to keep numbering continuous
    const { data: lastEntry, error: lastEntryError } = await supabase
      .from('montage_entries')
      .select('plan_number, order_index')
      .eq('sheet_id', sheetId)
      .order('plan_number', { ascending: false })
      .limit(1);
    
    if (lastEntryError) {
      console.error('Error fetching last plan number:', lastEntryError);
      throw new Error('Failed to fetch last plan number');
    }
    
    const lastPlanNumber = lastEntry?.[0]?.plan_number ?? 0;
    const lastOrderIndex = lastEntry?.[0]?.order_index ?? -1;

    // Insert parsed scenes into database
    const entriesToInsert = parsedScenes.map((scene, index) => ({
      sheet_id: sheetId,
      plan_number: lastPlanNumber + index + 1,
      order_index: lastOrderIndex + index + 1,
      start_timecode: scene.start_timecode,
      end_timecode: scene.end_timecode,
      plan_type: scene.plan_type || '',
      description: scene.description || '',
      dialogues: scene.dialogues || '',
    }));

    if (entriesToInsert.length > 0) {
      const { error: insertError } = await supabase
        .from('montage_entries')
        .insert(entriesToInsert);

      if (insertError) {
        // Check if it's a duplicate key error (from parallel processing)
        if (insertError.code === '23505') {
          console.warn(`‚ö†Ô∏è  Duplicate entries detected for chunk ${chunkIndex} (parallel processing), ignoring...`);
          // Don't throw error - this chunk was already processed by another request
        } else {
          console.error(`Error inserting entries for chunk ${chunkIndex}:`, insertError);
          throw new Error(`Failed to insert montage entries for chunk ${chunkIndex}`);
        }
      }
    }

    // Update chunk status to completed
    chunkProgress.chunks[chunkIndex].status = 'completed';
    chunkProgress.completedChunks += 1;
    
    await supabase
      .from('videos')
      .update({ chunk_progress_json: chunkProgress })
      .eq('id', videoId);

    console.log(`‚úÖ Chunk ${chunkIndex} completed: ${parsedScenes.length} scenes saved`);

    return NextResponse.json({
      success: true,
      chunkIndex,
      scenesCount: parsedScenes.length,
      completedChunks: chunkProgress.completedChunks,
      totalChunks: chunkProgress.totalChunks,
    });

  } catch (error) {
    console.error('Error processing chunk:', error);
    
    // Update chunk status to failed using variables from outer scope
    if (videoId && chunkIndex !== undefined) {
      try {
        const supabase = createServiceRoleClient();
        const { data: video } = await supabase
          .from('videos')
          .select('chunk_progress_json')
          .eq('id', videoId)
          .single();
        
        if (video?.chunk_progress_json) {
          const chunkProgress = video.chunk_progress_json;
          if (chunkProgress.chunks[chunkIndex]) {
            chunkProgress.chunks[chunkIndex].status = 'failed';
            await supabase
              .from('videos')
              .update({ chunk_progress_json: chunkProgress })
              .eq('id', videoId);
            console.log(`‚úÖ Updated chunk ${chunkIndex} status to failed`);
          }
        }
      } catch (updateError) {
        console.error('Could not update chunk status to failed:', updateError);
      }
    }

    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}

