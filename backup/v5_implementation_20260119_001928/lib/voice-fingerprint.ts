/**
 * Voice Fingerprint Module
 * 
 * Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ TitaNet Ğ¾Ñ‚ NVIDIA (Ñ‡ĞµÑ€ĞµĞ· Replicate) Ğ´Ğ»Ñ:
 * 1. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ voice embeddings Ğ¸Ğ· Ğ°ÑƒĞ´Ğ¸Ğ¾
 * 2. Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ² Ğ´Ğ»Ñ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹
 * 3. ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸ speaker â†’ character mapping
 */

import Replicate from 'replicate';

// TitaNet Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° Replicate
const TITANET_MODEL = 'adirik/titanet-large';

/**
 * Voice embedding â€” Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ³Ğ¾Ğ»Ğ¾ÑĞ°
 */
export interface VoiceEmbedding {
  characterName: string;
  embedding: number[];        // 192-dim vector Ğ¾Ñ‚ TitaNet
  sampleTimecode: string;     // ĞšĞ¾Ğ³Ğ´Ğ° Ğ±Ñ‹Ğ» Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½ Ğ¾Ğ±Ñ€Ğ°Ğ·ĞµÑ†
  confidence: number;         // Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ (0-1)
}

/**
 * Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²
 */
export interface VoiceMatch {
  characterName: string;
  similarity: number;         // Cosine similarity (0-1)
  isMatch: boolean;           // similarity > threshold
}

/**
 * ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾
 */
export interface VoiceCalibrationData {
  videoId: string;
  embeddings: VoiceEmbedding[];
  createdAt: number;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ĞĞ¡ĞĞĞ’ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ voice embedding Ğ¸Ğ· Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
 * 
 * @param audioUrl - URL Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
 * @param replicate - Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ Replicate ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°
 * @returns embedding vector (192 dimensions)
 */
export async function extractVoiceEmbedding(
  audioUrl: string,
  replicate: Replicate
): Promise<number[]> {
  console.log(`ğŸ¤ TitaNet: Extracting voice embedding...`);
  console.log(`   Audio: ${audioUrl.substring(0, 60)}...`);
  
  try {
    const output = await replicate.run(TITANET_MODEL as `${string}/${string}`, {
      input: {
        audio: audioUrl,
      },
    });
    
    // TitaNet Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ embedding ĞºĞ°Ğº Ğ¼Ğ°ÑÑĞ¸Ğ² Ñ‡Ğ¸ÑĞµĞ»
    if (Array.isArray(output)) {
      console.log(`   âœ… Embedding extracted: ${output.length} dimensions`);
      return output as number[];
    }
    
    // Ğ˜Ğ»Ğ¸ ĞºĞ°Ğº Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ñ Ğ¿Ğ¾Ğ»ĞµĞ¼ embedding
    if (output && typeof output === 'object' && 'embedding' in output) {
      const embedding = (output as { embedding: number[] }).embedding;
      console.log(`   âœ… Embedding extracted: ${embedding.length} dimensions`);
      return embedding;
    }
    
    console.error(`   âŒ Unexpected TitaNet output:`, output);
    throw new Error('TitaNet returned unexpected format');
  } catch (error) {
    console.error(`   âŒ TitaNet error:`, error);
    throw error;
  }
}

/**
 * Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ cosine similarity Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ´Ğ²ÑƒĞ¼Ñ embeddings
 */
export function cosineSimilarity(a: number[], b: number[]): number {
  if (a.length !== b.length) {
    throw new Error(`Embedding dimensions mismatch: ${a.length} vs ${b.length}`);
  }
  
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  
  if (normA === 0 || normB === 0) return 0;
  
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

/**
 * ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğ¹ Ğ³Ğ¾Ğ»Ğ¾Ñ Ğ¸Ğ· ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
 * 
 * @param embedding - embedding Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ°
 * @param calibration - ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğµ embeddings Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹
 * @param threshold - Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ° (default: 0.75)
 * @returns Ğ»ÑƒÑ‡ÑˆĞµĞµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ¸Ğ»Ğ¸ null
 */
export function findBestVoiceMatch(
  embedding: number[],
  calibration: VoiceCalibrationData,
  threshold: number = 0.75
): VoiceMatch | null {
  if (!calibration.embeddings || calibration.embeddings.length === 0) {
    return null;
  }
  
  let bestMatch: VoiceMatch | null = null;
  let bestSimilarity = -1;
  
  for (const voiceEmbed of calibration.embeddings) {
    const similarity = cosineSimilarity(embedding, voiceEmbed.embedding);
    
    if (similarity > bestSimilarity) {
      bestSimilarity = similarity;
      bestMatch = {
        characterName: voiceEmbed.characterName,
        similarity,
        isMatch: similarity >= threshold,
      };
    }
  }
  
  if (bestMatch) {
    console.log(`   ğŸ¯ Best voice match: ${bestMatch.characterName} (${(bestMatch.similarity * 100).toFixed(1)}%)`);
  }
  
  return bestMatch;
}

/**
 * Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ Ğ¸Ğ· Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ³Ğ¾Ğ»Ğ¾ÑĞ°
 * 
 * @param videoUrl - URL Ğ²Ğ¸Ğ´ĞµĞ¾
 * @param startMs - Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ² Ğ¼Ğ¸Ğ»Ğ»Ğ¸ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
 * @param endMs - ĞºĞ¾Ğ½ĞµÑ† Ğ² Ğ¼Ğ¸Ğ»Ğ»Ğ¸ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
 * @returns URL Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
 */
export async function extractAudioSegment(
  videoUrl: string,
  startMs: number,
  endMs: number
): Promise<string> {
  // TODO: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°
  // ĞŸĞ¾ĞºĞ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ URL (Ğ±ÑƒĞ´ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ²ĞµÑÑŒ Ñ‡Ğ°Ğ½Ğº)
  console.log(`   ğŸ“ Audio segment: ${startMs}ms - ${endMs}ms`);
  return videoUrl;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ĞšĞĞ›Ğ˜Ğ‘Ğ ĞĞ’ĞšĞ
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * ĞšĞ°Ğ»Ğ¸Ğ±Ñ€ÑƒĞµÑ‚ Ğ³Ğ¾Ğ»Ğ¾ÑĞ° Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹ Ğ¸Ğ· Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ°
 * 
 * Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°:
 * 1. Gemini Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ĞºÑ‚Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾
 * 2. TitaNet Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ embedding Ğ³Ğ¾Ğ»Ğ¾ÑĞ° Ğ² ÑÑ‚Ğ¾Ñ‚ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚
 * 3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ñƒ: Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ â†’ embedding
 */
export async function calibrateVoicesFromChunk(
  scenes: Array<{
    start_timecode: string;
    end_timecode: string;
    description: string;
    dialogues: string;
  }>,
  speakerWords: Array<{
    word: string;
    start: number;
    end: number;
    speaker: string;
  }>,
  audioUrl: string,
  knownCharacters: string[],
  replicate: Replicate,
  timecodeToSeconds: (tc: string) => number
): Promise<VoiceEmbedding[]> {
  const embeddings: VoiceEmbedding[] = [];
  const calibratedCharacters = new Set<string>();
  
  console.log(`\nğŸ¤ VOICE CALIBRATION: Extracting voice fingerprints...`);
  
  // ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ†ĞµĞ½Ñ‹ Ğ³Ğ´Ğµ Gemini Ñ‡Ñ‘Ñ‚ĞºĞ¾ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ» Ğ³Ğ¾Ğ²Ğ¾Ñ€ÑÑ‰ĞµĞ³Ğ¾
  const scenesWithSpeaker = scenes.filter(s => {
    const dialogueUpper = s.dialogues?.toUpperCase() || '';
    // Ğ˜Ñ‰ĞµĞ¼ ÑÑ†ĞµĞ½Ñ‹ Ğ³Ğ´Ğµ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ñ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶Ğ°
    return knownCharacters.some(c => dialogueUpper.startsWith(c));
  });
  
  console.log(`   Found ${scenesWithSpeaker.length} scenes with identified speakers`);
  
  for (const scene of scenesWithSpeaker.slice(0, 5)) { // Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 5 Ğ´Ğ»Ñ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸
    // ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶Ğ° Ğ¸Ğ· Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°
    const dialogueUpper = scene.dialogues?.toUpperCase() || '';
    const character = knownCharacters.find(c => dialogueUpper.startsWith(c));
    
    if (!character || calibratedCharacters.has(character)) continue;
    
    // ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ÑÑ†ĞµĞ½Ñ‹
    const sceneStartMs = timecodeToSeconds(scene.start_timecode) * 1000;
    const sceneEndMs = timecodeToSeconds(scene.end_timecode) * 1000;
    
    // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ñ€ĞµÑ‡ÑŒ Ğ² ÑÑ‚Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ
    const wordsInScene = speakerWords.filter(w => 
      w.start >= sceneStartMs - 500 && w.end <= sceneEndMs + 500
    );
    
    if (wordsInScene.length < 3) {
      console.log(`   âš ï¸ ${character}: not enough speech in scene`);
      continue;
    }
    
    console.log(`   ğŸ¤ Calibrating ${character} from ${scene.start_timecode}...`);
    
    try {
      // Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ embedding Ğ³Ğ¾Ğ»Ğ¾ÑĞ°
      // ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ: TitaNet Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾, Ğ¼Ñ‹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ URL Ñ‡Ğ°Ğ½ĞºĞ°
      const embedding = await extractVoiceEmbedding(audioUrl, replicate);
      
      embeddings.push({
        characterName: character,
        embedding,
        sampleTimecode: scene.start_timecode,
        confidence: 0.8, // ĞĞ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
      });
      
      calibratedCharacters.add(character);
      console.log(`   âœ… ${character}: voice fingerprint saved`);
      
    } catch (error) {
      console.error(`   âŒ ${character}: calibration failed:`, error);
    }
  }
  
  console.log(`\nğŸ“Š Voice calibration complete: ${embeddings.length} characters`);
  for (const e of embeddings) {
    console.log(`   â€¢ ${e.characterName} (confidence: ${(e.confidence * 100).toFixed(0)}%)`);
  }
  
  return embeddings;
}

/**
 * Ğ˜Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ¿Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑÑƒ
 */
export async function identifySpeakerByVoice(
  audioUrl: string,
  calibration: VoiceCalibrationData,
  replicate: Replicate,
  threshold: number = 0.75
): Promise<string | null> {
  if (!calibration.embeddings || calibration.embeddings.length === 0) {
    return null;
  }
  
  try {
    const embedding = await extractVoiceEmbedding(audioUrl, replicate);
    const match = findBestVoiceMatch(embedding, calibration, threshold);
    
    if (match && match.isMatch) {
      return match.characterName;
    }
    
    return null;
  } catch (error) {
    console.error(`Voice identification failed:`, error);
    return null;
  }
}

/**
 * Ğ¡ĞµÑ€Ğ¸Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ² Ğ‘Ğ”
 */
export function serializeCalibration(data: VoiceCalibrationData): string {
  return JSON.stringify(data);
}

/**
 * Ğ”ĞµÑĞµÑ€Ğ¸Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ‘Ğ”
 */
export function deserializeCalibration(json: string): VoiceCalibrationData | null {
  try {
    return JSON.parse(json) as VoiceCalibrationData;
  } catch {
    return null;
  }
}
