/**
 * Init Processing V5 â€” Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° (BETA)
 * 
 * ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¾Ñ‚ V4:
 * 1. Ğ¡ĞĞĞ§ĞĞ›Ğ Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾-Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (Ğ²ĞµÑÑŒ Ñ„Ğ¸Ğ»ÑŒĞ¼)
 * 2. ASRâ†”Script alignment Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°
 * 3. Speakerâ†’Character Ñ no-jumps Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾Ğ¼
 * 4. Face presence Ñ 3 ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸ÑĞ¼Ğ¸
 * 5. Overlap dedup Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ speech_segments
 * 
 * Gemini Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ´Ğ»Ñ:
 * - Ğ¢Ğ¸Ğ¿ Ğ¿Ğ»Ğ°Ğ½Ğ° (ĞšÑ€./Ğ¡Ñ€./ĞĞ±Ñ‰.)
 * - ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ†ĞµĞ½Ñ‹
 * - Visual tags (ĞĞ• Ğ´Ğ»Ñ "ĞºÑ‚Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚")
 * 
 * @author AI Assistant
 * @version 5.0-beta
 */

import { createServiceRoleClient } from '@/lib/supabase/server';
import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';
import { createVideoChunks } from '@/lib/video-chunking';
import { downloadVideo, splitVideoIntoChunks, cleanupTempFiles } from '@/lib/video-splitter';
import { detectVideoFPS } from '@/lib/scene-detection';
import { 
  detectScenesWithPySceneDetect, 
  validatePySceneDetect,
} from '@/lib/pyscenedetect';
import { mergeCreditsScenes } from '@/lib/credits-detector';
import { smartMergeScenes } from '@/lib/smart-scene-merger';
import { 
  groupWordsIntoSegments, 
  alignASRToScript,
  type ASRWord,
} from '@/lib/asr-script-alignment';
import { 
  SpeakerCharacterMapper, 
  logMappingStats,
} from '@/lib/speaker-character-mapper';
import { type ScriptLine } from '@/lib/script-parser-deterministic';
import path from 'path';
import fs from 'fs';

// Feature flags
const USE_FACE_RECOGNITION = process.env.USE_FACE_RECOGNITION === 'true';
const USE_FULL_DIARIZATION = true; // V5 Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

// Dynamic import types
type FaceCluster = {
  clusterId: string;
  appearances: number;
  firstSeen: number;
  lastSeen: number;
  characterName?: string | null;
  centroid?: Float32Array | number[];
  faces?: Array<{ timestamp: number }>;
  faceTimestamps?: number[];  // Timestamps Ğ»Ğ¸Ñ† (ÑĞµĞº) - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ĞºĞ¾Ğ³Ğ´Ğ° faces Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
};

// 10 minutes timeout (V5 Ğ´ĞµĞ»Ğ°ĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹)
export const maxDuration = 600;
export const dynamic = 'force-dynamic';

export async function POST(request: NextRequest) {
  const tempFiles: string[] = [];
  const startTime = Date.now();
  
  // Use internal URL for Railway (HTTP inside container)
  // Railway exposes the app on PORT internally, but uses HTTPS externally
  const requestUrl = new URL(request.url);
  const isRailway = !!process.env.RAILWAY_ENVIRONMENT;
  const savedBaseUrl = isRailway 
    ? `http://localhost:${process.env.PORT || 3000}`
    : `${requestUrl.protocol}//${requestUrl.host}`;
  
  try {
    const { videoId, videoUrl, videoDuration, filmMetadata, scriptData } = await request.json();

    if (!videoId || !videoUrl || !videoDuration) {
      return NextResponse.json(
        { error: 'Missing required fields: videoId, videoUrl, videoDuration' },
        { status: 400 }
      );
    }

    console.log(`\n${'â•'.repeat(70)}`);
    console.log(`ğŸš€ V5 BETA INIT â€” Improved Architecture`);
    console.log(`${'â•'.repeat(70)}`);
    console.log(`   Video: ${videoId}`);
    console.log(`   Duration: ${videoDuration}s (${(videoDuration / 60).toFixed(1)} min)`);
    console.log(`   Face Recognition: ${USE_FACE_RECOGNITION ? 'ENABLED' : 'disabled'}`);
    console.log(`   Full Diarization: ${USE_FULL_DIARIZATION ? 'ENABLED' : 'disabled'}`);
    
    // Log script data
    const hasScript = scriptData?.characters?.length > 0;
    const scriptLines: ScriptLine[] = scriptData?.lines || [];
    
    if (hasScript) {
      console.log(`\nğŸ“‹ SCRIPT DATA:`);
      console.log(`   Characters: ${scriptData.characters.length}`);
      console.log(`   Lines: ${scriptLines.length}`);
      const mainChars = scriptData.characters.filter((c: any) => c.dialogueCount >= 5);
      if (mainChars.length > 0) {
        console.log(`   Main: ${mainChars.slice(0, 5).map((c: any) => c.name).join(', ')}`);
      }
    } else {
      console.log(`\nâš ï¸  No script provided â€” character identification will be limited`);
    }

    const supabase = createServiceRoleClient();

    // Atomic lock
    const { data: lockResult, error: lockError } = await supabase
      .from('videos')
      .update({ 
        status: 'processing',
        chunk_progress_json: { 
          initializing: true, 
          timestamp: new Date().toISOString(), 
          processingVersion: 'v5-beta',
          architecture: 'improved',
        }
      })
      .eq('id', videoId)
      .eq('status', 'processing')
      .is('chunk_progress_json', null)
      .select('user_id');

    if (!lockResult || lockResult.length === 0) {
      console.log(`âš ï¸  Video ${videoId} is already being initialized`);
      
      const { data: existingVideo } = await supabase
        .from('videos')
        .select('chunk_progress_json')
        .eq('id', videoId)
        .single();
      
      return NextResponse.json({
        success: true,
        videoId,
        message: 'Already initializing (duplicate blocked)',
        progress: existingVideo?.chunk_progress_json,
      });
    }

    console.log(`\nğŸ”’ Lock acquired for ${videoId}`);
    const video = lockResult[0];

    // Create chunks
    const chunks = createVideoChunks(videoDuration);
    console.log(`ğŸ“¦ Created ${chunks.length} chunks`);

    // Create/get montage sheet
    const { data: existingSheet } = await supabase
      .from('montage_sheets')
      .select('*')
      .eq('video_id', videoId)
      .maybeSingle();

    let sheet;
    if (existingSheet) {
      sheet = existingSheet;
    } else {
      const { data: newSheet, error: sheetError } = await supabase
        .from('montage_sheets')
        .insert({
          video_id: videoId,
          user_id: video.user_id,
          title: `ĞœĞ¾Ğ½Ñ‚Ğ°Ğ¶Ğ½Ñ‹Ğ¹ Ğ»Ğ¸ÑÑ‚ V5 BETA (${chunks.length} Ñ‡Ğ°ÑÑ‚ĞµĞ¹)`,
        })
        .select()
        .single();

      if (sheetError || !newSheet) {
        throw new Error('Failed to create montage sheet');
      }
      sheet = newSheet;
    }

    // Initialize chunk progress with V5 markers
    const chunkProgress: any = {
      totalChunks: chunks.length,
      completedChunks: 0,
      currentChunk: 0,
      sheetId: sheet.id,
      processingVersion: 'v5-beta',
      architecture: 'improved',
      sceneDetector: 'pyscenedetect',
      scriptData: scriptData || null,
      chunks: chunks.map(chunk => ({
        index: chunk.chunkIndex,
        status: 'pending' as const,
        startTimecode: chunk.startTimecode,
        endTimecode: chunk.endTimecode,
        storageUrl: null as string | null,
      })),
      // V5-specific fields
      speakerCharacterMap: {},
      speechSegments: [],
      alignmentStats: null,
    };

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 1: Download video
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    const tempDir = '/tmp/video-chunks-v5';
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    
    const originalVideoPath = path.join(tempDir, `original_${videoId}.mp4`);
    console.log(`\nğŸ“¥ STEP 1: Downloading video...`);
    await downloadVideo(videoUrl, originalVideoPath);
    tempFiles.push(originalVideoPath);
    
    // Detect FPS
    let videoFPS = 24;
    try {
      videoFPS = await detectVideoFPS(originalVideoPath);
      console.log(`   FPS: ${videoFPS}`);
    } catch (e) {
      console.warn(`   âš ï¸ Could not detect FPS, using default ${videoFPS}`);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 2: Full Audio Diarization (Ğ’Ğ•Ğ¡Ğ¬ Ğ¤Ğ˜Ğ›Ğ¬Ğœ Ğ¡Ğ ĞĞ—Ğ£)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    console.log(`\nğŸ¤ STEP 2: Full Audio Diarization (entire video)...`);
    
    let fullDiarizationWords: ASRWord[] = [];
    let speakerCharacterMapper = new SpeakerCharacterMapper();
    
    if (USE_FULL_DIARIZATION && process.env.ASSEMBLYAI_API_KEY) {
      try {
        const { performFullDiarization } = await import('@/lib/full-audio-diarization');
        
        const characterNames = hasScript 
          ? scriptData.characters.map((c: any) => c.name).slice(0, 15)
          : [];
        
        // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ
        // Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ ASR Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ´ĞºĞ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°
        // Ğ£ĞĞ˜Ğ’Ğ•Ğ Ğ¡ĞĞ›Ğ¬ĞĞ«Ğ™ ÑĞ¿Ğ¸ÑĞ¾Ğº: Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°, ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°
        // ĞŸĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶Ğ¸ ÑƒĞ¶Ğµ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹ Ğ² characterNames, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°
        const UNIVERSAL_BOOST_WORDS = [
          // Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²ĞµĞ¶Ğ»Ğ¸Ğ²Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ»Ğ¾Ğ²Ğ°, Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ğµ Ğ² Ñ„Ğ¸Ğ»ÑŒĞ¼Ğ°Ñ…
          'Ğ¼Ğ¸Ğ½ÑƒÑ‚Ğ¾Ñ‡ĞºÑƒ', 'Ğ¿Ğ°Ñ€Ğ´Ğ¾Ğ½', 'Ğ¿Ñ€Ğ¸ÑĞ°Ğ¶Ğ¸Ğ²Ğ°Ğ¹Ñ‚ĞµÑÑŒ', 'Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ',
        ];
        
        // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¸Ğ¼ĞµĞ½Ğ° Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹ Ğ¸Ğ· ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ñ + ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°
        // ĞĞ• Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ¸Ğ»ÑŒĞ¼Ğ°!
        const allBoostWords = [...characterNames, ...UNIVERSAL_BOOST_WORDS].slice(0, 20);
        console.log(`   ğŸ“ Word boost: ${allBoostWords.join(', ')}`);
        
        const diarizationResult = await performFullDiarization(
          videoUrl,
          'ru',
          allBoostWords,  // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº
          15  // Ğ£Ğ’Ğ•Ğ›Ğ˜Ğ§Ğ•ĞĞ Ñ 10 Ğ´Ğ¾ 15 Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²
        );
        
        console.log(`   âœ… Diarization complete:`);
        console.log(`      Words: ${diarizationResult.words.length}`);
        console.log(`      Speakers: ${diarizationResult.speakers.join(', ')}`);
        console.log(`      Duration: ${(diarizationResult.totalDuration / 60).toFixed(1)} min`);
        
        // Convert to ASRWord format (AssemblyAI uses 'word', we use 'text')
        fullDiarizationWords = diarizationResult.words.map(w => ({
          text: w.word,  // AssemblyAI field is 'word', not 'text'
          startMs: w.start,
          endMs: w.end,
          confidence: w.confidence,
          speaker: w.speaker,
        }));
        
        // ğŸ”’ Save diarization IMMEDIATELY (before potentially failing alignment)
        chunkProgress.fullDiarizationWords = fullDiarizationWords.slice(0, 50000);
        console.log(`   ğŸ’¾ Saved ${fullDiarizationWords.length} words to chunk progress`);
        
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // STEP 3: ASRâ†”Script Alignment (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹)
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if (hasScript && scriptLines.length > 0) {
          console.log(`\nğŸ“ STEP 3: ASRâ†”Script Alignment...`);
          
          const asrSegments = groupWordsIntoSegments(fullDiarizationWords);
          console.log(`   ASR segments: ${asrSegments.length}`);
          
          // ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ ÑÑ†ĞµĞ½Ñ‹ Ğ´Ğ»Ñ scene context evidence
          const scriptScenes = scriptData?.scenes || [];
          const alignmentResult = alignASRToScript(asrSegments, scriptLines, scriptScenes);
          
          console.log(`   âœ… Alignment complete:`);
          console.log(`      Matched: ${alignmentResult.totalMatched}`);
          console.log(`      Unmatched: ${alignmentResult.totalUnmatched}`);
          console.log(`      Anchors: ${alignmentResult.anchorCount}`);
          
          // Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ scene context Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
          const linksWithSceneContext = alignmentResult.links.filter(l => l.sceneCharacters && l.sceneCharacters.length > 0);
          if (linksWithSceneContext.length > 0) {
            console.log(`      Scene context: ${linksWithSceneContext.length} links have character lists`);
          }
          
          // Build speakerâ†’character mapping
          speakerCharacterMapper.addAlignmentEvidence(alignmentResult);
          
          chunkProgress.alignmentStats = {
            totalMatched: alignmentResult.totalMatched,
            totalUnmatched: alignmentResult.totalUnmatched,
            anchorCount: alignmentResult.anchorCount,
          };
        }
        
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // STEP 3.2: Name Mention Calibration (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸ÑĞ¼ Ğ¸Ğ¼Ñ‘Ğ½)
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if (hasScript && fullDiarizationWords.length > 0 && scriptData.characters.length > 0) {
          console.log(`\nğŸ“› STEP 3.2: Name Mention Calibration...`);
          
          try {
            const { calibrateSpeakersByNameMentions } = await import('@/lib/face-speaker-binding');
            
            // ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ° Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ´Ğ»Ñ calibration
            const diarizationWordsForCalibration = fullDiarizationWords
              .filter(w => w.speaker) // Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ° Ğ±ĞµĞ· speaker
              .map(w => ({
                text: w.text,
                start: w.startMs,
                end: w.endMs,
                speaker: w.speaker!,
              }));
            
            // ĞšĞ°Ğ»Ğ¸Ğ±Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸ÑĞ¼ Ğ¸Ğ¼Ñ‘Ğ½ (Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ñ€Ğ¾Ğ»Ğ¸ Ñ‚Ğ¸Ğ¿Ğ° "ĞœĞµĞ½ĞµĞ´Ğ¶ĞµÑ€")
            const nameMentionMapping = calibrateSpeakersByNameMentions(
              diarizationWordsForCalibration,
              scriptData.characters.map((c: any) => ({
                name: c.name,
                variants: c.variants || [],
              }))
            );
            
            // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ° Ğ² mapper
            for (const [speakerId, characterName] of nameMentionMapping) {
              speakerCharacterMapper.addNameMention(speakerId, characterName, 0);
            }
            
            console.log(`   âœ… Name mention calibration: ${nameMentionMapping.size} speakers mapped`);
          } catch (nameMentionError) {
            console.error(`   âš ï¸ Name mention calibration failed:`, nameMentionError);
            console.log(`   Continuing without name mention calibration...`);
          }
        }
        
        // Build final mapping
        const mappingResult = speakerCharacterMapper.buildMapping();
        logMappingStats(mappingResult);
        
        // Store mapping for chunk processing
        chunkProgress.speakerCharacterMap = speakerCharacterMapper.export();
        
      } catch (diarError) {
        console.error(`   âŒ Diarization failed:`, diarError);
        console.log(`   Continuing without full diarization...`);
      }
    } else {
      console.log(`   âš ï¸ Full diarization skipped (no ASSEMBLYAI_API_KEY)`);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 3.5: Voice Embeddings (Ğ´Ğ»Ñ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ñ speakerâ†’character)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    const USE_VOICE_EMBEDDINGS = process.env.USE_VOICE_EMBEDDINGS === 'true';
    
    if (USE_VOICE_EMBEDDINGS && fullDiarizationWords.length > 0) {
      console.log(`\nğŸ¤ STEP 3.5: Voice Embeddings...`);
      
      try {
        const { createVoiceEmbeddings, refineSpeakerMapping } = await import('@/lib/voice-embeddings');
        
        const voiceResult = await createVoiceEmbeddings(
          originalVideoPath,
          fullDiarizationWords as any[]
        );
        
        if (voiceResult.embeddings && Object.keys(voiceResult.embeddings).length > 0) {
          console.log(`   âœ… Created voice embeddings for ${voiceResult.speaker_count} speakers`);
          
          // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ embeddings Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
          chunkProgress.voiceEmbeddings = voiceResult.embeddings;
          
          // Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ matches â€” ÑƒÑ‚Ğ¾Ñ‡Ğ½ÑĞµĞ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³
          if (voiceResult.matches) {
            const currentMapping = speakerCharacterMapper.getMapping();
            const refinedMapping = refineSpeakerMapping(
              Object.fromEntries(currentMapping),
              voiceResult.matches,
              0.8  // confidence threshold
            );
            
            // ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³
            for (const [speakerId, characterName] of Object.entries(refinedMapping)) {
              speakerCharacterMapper.setManualMapping(speakerId, characterName);
            }
          }
        }
      } catch (voiceError) {
        console.error(`   âŒ Voice embeddings failed:`, voiceError);
        console.log(`   Continuing without voice embeddings...`);
      }
    } else if (!USE_VOICE_EMBEDDINGS) {
      console.log(`\nğŸ¤ STEP 3.5: Voice Embeddings skipped (USE_VOICE_EMBEDDINGS=false)`);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 4: Face Recognition (optional)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    let faceClusters: FaceCluster[] = [];
    
    if (USE_FACE_RECOGNITION) {
      console.log(`\nğŸ­ STEP 4: Face Recognition...`);
      
      try {
        const { clusterFacesInVideoWorker } = await import('@/lib/face-clustering');
        
        faceClusters = await clusterFacesInVideoWorker(originalVideoPath, {
          frameInterval: 5,
          distanceThreshold: 0.5,
          minAppearances: 5,
        });
        
        console.log(`   âœ… Found ${faceClusters.length} unique faces`);
        
        // Auto-bind faces to characters based on frequency
        if (hasScript && faceClusters.length > 0) {
          const sortedClusters = [...faceClusters].sort((a, b) => b.appearances - a.appearances);
          // Ğ£Ğ›Ğ£Ğ§Ğ¨Ğ•ĞĞ: Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ’Ğ¡Ğ•Ğ¥ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹ Ğ¸Ğ· ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ñ (Ğ±ĞµĞ· Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ° Ğ¿Ğ¾ Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ğ¼)
          // Ğ›ÑĞ±Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ² ÑÑ†ĞµĞ½Ğµ â€” Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ ĞµÑĞ»Ğ¸ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚
          const allCharacters = scriptData.characters
            .sort((a: { dialogueCount?: number }, b: { dialogueCount?: number }) =>
              (b.dialogueCount || 0) - (a.dialogueCount || 0)
            );
          
          // ĞŸÑ€Ğ¸Ğ²ÑĞ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ»Ğ¸Ñ†, ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ĞµÑÑ‚ÑŒ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹ (Ğ±ĞµĞ· Ğ¶Ñ‘ÑÑ‚ĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°)
          const boundCount = Math.min(sortedClusters.length, allCharacters.length);
          for (let i = 0; i < boundCount; i++) {
            sortedClusters[i].characterName = allCharacters[i].name?.toUpperCase();
          }
          
          console.log(`   ğŸ”— Auto-bound ${boundCount} faces to characters (all from script)`);
        }
        
      } catch (faceError) {
        console.error(`   âŒ Face recognition failed:`, faceError);
      }
    } else {
      console.log(`\nâ„¹ï¸  Face Recognition disabled`);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 4.5: Face Presence Evidence (ÑĞ²ÑĞ·ÑŒ Ğ»Ğ¸Ñ† Ñ Ğ³Ğ¾Ğ»Ğ¾ÑĞ°Ğ¼Ğ¸)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if (faceClusters.length > 0 && fullDiarizationWords.length > 0) {
      console.log(`\nğŸ”— STEP 4.5: Building Face Presence Evidence...`);
      
      try {
        // Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ face presence evidence Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
        const facePresenceEvidence: Array<{
          speakerId: string;
          faceClusterId: string;
          characterName?: string;
          startMs: number;
          endMs: number;
          dominance: number;
        }> = [];
        
        // Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ° Ğ¿Ğ¾ speaker Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸
        const wordsBySpeaker = new Map<string, typeof fullDiarizationWords>();
        for (const word of fullDiarizationWords) {
          if (!word.speaker) continue;
          const existing = wordsBySpeaker.get(word.speaker) || [];
          existing.push(word);
          wordsBySpeaker.set(word.speaker, existing);
        }
        
        // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ² Ğ¸Ğ¼ĞµÑÑ‚ characterName
        const clustersWithName = faceClusters.filter(c => c.characterName);
        console.log(`   ğŸ“Š Face clusters with characterName: ${clustersWithName.length}/${faceClusters.length}`);
        if (clustersWithName.length > 0) {
          console.log(`   ğŸ“‹ Bound characters: ${clustersWithName.map(c => c.characterName).join(', ')}`);
          
          // Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°: Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ faces
          const clustersWithTimestamps = clustersWithName.filter(c => {
            const hasFaces = c.faces && c.faces.length > 0;
            const hasTimestamps = c.faceTimestamps && c.faceTimestamps.length > 0;
            return hasFaces || hasTimestamps;
          });
          console.log(`   ğŸ” Clusters with timestamps: ${clustersWithTimestamps.length}/${clustersWithName.length}`);
          if (clustersWithTimestamps.length > 0) {
            const sampleCluster = clustersWithTimestamps[0];
            const timestamps = sampleCluster.faces && sampleCluster.faces.length > 0
              ? sampleCluster.faces.map(f => f.timestamp)
              : (sampleCluster.faceTimestamps || []);
            const count = sampleCluster.faces?.length || sampleCluster.faceTimestamps?.length || 0;
            console.log(`   ğŸ“‹ Sample cluster: ${sampleCluster.clusterId} (${sampleCluster.characterName}), ${count} timestamps, first: ${timestamps[0]?.toFixed(1) || 'N/A'}s`);
          }
        }
        
        // Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ speaker Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ĞºĞ°ĞºĞ¸Ğµ Ğ»Ğ¸Ñ†Ğ° Ğ±Ñ‹Ğ»Ğ¸ Ğ²Ğ¸Ğ´Ğ½Ñ‹ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ ĞµĞ³Ğ¾ Ñ€ĞµÑ‡Ğ¸
        let processedSpeakers = 0;
        for (const [speakerId, words] of wordsBySpeaker) {
          // Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°: Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 3 speakers
          if (processedSpeakers < 3) {
            const sampleWord = words[0];
            if (sampleWord) {
              console.log(`   ğŸ” Processing Speaker ${speakerId}: ${words.length} words, first word at ${sampleWord.startMs / 1000}s`);
            }
          }
          processedSpeakers++;
          
          // Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°Ğ· ĞºĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ»Ğ¸Ñ†Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ²Ğ¸Ğ´Ğ½Ğ¾ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ñ€ĞµÑ‡Ğ¸ ÑÑ‚Ğ¾Ğ³Ğ¾ speaker
          const facePresenceCounts = new Map<string, number>();
          
          for (const word of words) {
            const wordStartSec = word.startMs / 1000;
            const wordEndSec = word.endMs / 1000;
            
            for (const cluster of faceClusters) {
              if (!cluster.characterName) continue;
              
              // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ faceTimestamps ĞµÑĞ»Ğ¸ faces Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ (worker mode)
              const timestamps = cluster.faces && cluster.faces.length > 0
                ? cluster.faces.map(f => f.timestamp)
                : (cluster.faceTimestamps || []);
              
              if (timestamps.length === 0) continue;
              
              // Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹):
              // - Forward window: 3.5s (Ñ€ĞµÑ‡ÑŒ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒÑÑ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ğ¾ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ»Ğ¸Ñ†Ğ°)
              // - Backward window: 1.5s (Ğ»Ğ¸Ñ†Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ğ¾ÑĞ²Ğ¸Ñ‚ÑŒÑÑ Ñ‡ÑƒÑ‚ÑŒ Ñ€Ğ°Ğ½ÑŒÑˆĞµ Ñ€ĞµÑ‡Ğ¸)
              const FORWARD_WINDOW_FACE = 3.5;  // Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¾ Ñ 2s
              const BACKWARD_WINDOW_FACE = 1.5; // Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¾ Ñ 2s
              
              const facesInWindow = timestamps.filter(faceTime => {
                // Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°: Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ timestamps Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ
                if (isNaN(faceTime) || faceTime < 0) {
                  console.log(`   âš ï¸ Invalid face timestamp: ${faceTime} for cluster ${cluster.clusterId}`);
                  return false;
                }
                return faceTime >= wordStartSec - BACKWARD_WINDOW_FACE && 
                       faceTime <= wordEndSec + FORWARD_WINDOW_FACE;
              });
              
              if (facesInWindow.length > 0) {
                const count = facePresenceCounts.get(cluster.clusterId) || 0;
                facePresenceCounts.set(cluster.clusterId, count + facesInWindow.length);
              }
            }
          }
          
          // ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒÑÑ‰ĞµĞµ Ğ»Ğ¸Ñ†Ğ¾ Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ speaker
          let maxCount = 0;
          let dominantCluster: FaceCluster | null = null;
          
          for (const [clusterId, count] of facePresenceCounts) {
            if (count > maxCount) {
              maxCount = count;
              dominantCluster = faceClusters.find(c => c.clusterId === clusterId) || null;
            }
          }
          
          if (dominantCluster && dominantCluster.characterName) {
            const totalAppearances = Array.from(facePresenceCounts.values()).reduce((a, b) => a + b, 0);
            const dominance = totalAppearances > 0 ? maxCount / totalAppearances : 0;
            
            // Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… 3 speakers
            if (processedSpeakers <= 3) {
              console.log(`   ğŸ” Speaker ${speakerId}: dominant=${dominantCluster.characterName}, count=${maxCount}, total=${totalAppearances}, dominance=${(dominance * 100).toFixed(1)}%`);
            }
            
            // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ evidence ĞµÑĞ»Ğ¸ dominance > 0.3 (Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ 30% Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸)
            if (dominance > 0.3) {
              facePresenceEvidence.push({
                speakerId,
                faceClusterId: dominantCluster.clusterId,
                characterName: dominantCluster.characterName,
                startMs: words[0]?.startMs || 0,
                endMs: words[words.length - 1]?.endMs || 0,
                dominance,
              });
            }
          }
        }
        
        console.log(`   ğŸ” Found ${facePresenceEvidence.length} face presence evidence entries`);
        if (facePresenceEvidence.length > 0) {
          console.log(`   ğŸ“‹ Evidence samples (first 5):`);
          facePresenceEvidence.slice(0, 5).forEach(ev => {
            console.log(`      Speaker ${ev.speakerId} â†’ ${ev.characterName} (dominance: ${(ev.dominance * 100).toFixed(1)}%)`);
          });
        } else {
          console.log(`   âš ï¸ No face presence evidence found. Possible reasons:`);
          console.log(`      - Face clusters don't have characterName`);
          console.log(`      - Dominance threshold too high (< 30%)`);
          console.log(`      - Face timestamps don't align with speech`);
        }
        
        // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ face presence evidence Ğ² mapper
        if (facePresenceEvidence.length > 0) {
          speakerCharacterMapper.addFacePresenceEvidence(facePresenceEvidence);
          console.log(`   âœ… Added face presence evidence for ${facePresenceEvidence.length} speakers`);
          
          // ĞŸĞµÑ€ĞµÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ mapping Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼ evidence
          const newMappingResult = speakerCharacterMapper.buildMapping();
          chunkProgress.speakerCharacterMap = speakerCharacterMapper.export();
          logMappingStats(newMappingResult);
        }
      } catch (facePresenceError) {
        console.error(`   âš ï¸ Face presence evidence failed:`, facePresenceError);
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 5: PySceneDetect
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    console.log(`\nğŸ¬ STEP 5: Scene Detection (PySceneDetect)...`);
    
    let detectedScenes: Array<{ timecode: string; timestamp: number }> = [];
    
    try {
      const isPySceneDetectAvailable = await validatePySceneDetect();
      
      if (isPySceneDetectAvailable) {
        const rawScenes = await detectScenesWithPySceneDetect(originalVideoPath, { 
          fps: videoFPS,
          adaptiveThreshold: 1.8,
          minSceneDuration: 0.2,  // ĞĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ¸Ğ»Ğ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ° ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ¿Ğ»Ğ°Ğ½Ğ¾Ğ²
          maxScenes: 5000,
        });
        
        console.log(`   ğŸ“Š PySceneDetect RAW: ${rawScenes.length} scenes detected`);
        
        // ĞœĞ˜ĞĞ˜ĞœĞĞ›Ğ¬ĞĞ«Ğ™ Ğ¼ĞµÑ€Ğ´Ğ¶Ğ¸Ğ½Ğ³ â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹ (<0.08 ÑĞµĞº = 2 ĞºĞ°Ğ´Ñ€Ğ°)
        // Ğ­Ñ‚Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸, Ğ½Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ»Ğ°Ğ½Ñ‹
        const smartMerged = smartMergeScenes(rawScenes, {
          ultraShortThreshold: 0.08,  // <2 ĞºĞ°Ğ´Ñ€Ğ° Ğ¿Ñ€Ğ¸ 25fps â€” Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚
          shortThreshold: 0.08,       // ĞĞµ Ğ¼ĞµÑ€Ğ´Ğ¶Ğ¸Ğ¼ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ
        });
        
        detectedScenes = smartMerged.map(s => ({
          timecode: s.timecode,
          timestamp: s.timestamp,
        }));
        
        console.log(`   âœ… Detected ${detectedScenes.length} scene changes`);
        
        // Add closing scene
        const lastSceneTime = detectedScenes[detectedScenes.length - 1]?.timestamp || 0;
        if (videoDuration - lastSceneTime > 2.0) {
          const totalFrames = Math.round(videoDuration * videoFPS);
          const frames = ((totalFrames % videoFPS) + videoFPS) % videoFPS;
          const totalSeconds = Math.floor(totalFrames / videoFPS);
          const secs = totalSeconds % 60;
          const totalMinutes = Math.floor(totalSeconds / 60);
          const mins = totalMinutes % 60;
          const hours = Math.floor(totalMinutes / 60);
          const finalTimecode = `${hours.toString().padStart(2, '0')}:${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}:${frames.toString().padStart(2, '0')}`;
          detectedScenes.push({ timecode: finalTimecode, timestamp: videoDuration });
        }
        
        // ĞĞ£Ğ”Ğ˜Ğ-Ğ”Ğ•Ğ¢Ğ•ĞšĞ¦Ğ˜Ğ¯: ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°
        // Ğ—Ğ°ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ·Ğ°ĞºĞ°Ğ½Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ ĞºĞ¾Ğ³Ğ´Ğ° Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ÑÑ‚ÑÑ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¸!
        let firstDialogueTime: number | undefined;
        if (fullDiarizationWords.length > 0) {
          // Ğ˜Ñ‰ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ğ¾Ğµ "Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰ĞµĞµ" ÑĞ»Ğ¾Ğ²Ğ¾ (Ğ½Ğµ ÑˆÑƒĞ¼, Ğ½Ğµ Ğ¼ÑƒĞ·Ñ‹ĞºĞ°)
          const firstRealWord = fullDiarizationWords.find(w => 
            w.text && w.text.length >= 2 && /[Ğ°-ÑÑ‘a-z]/i.test(w.text)
          );
          if (firstRealWord) {
            firstDialogueTime = firstRealWord.startMs / 1000;
            console.log(`   ğŸ¤ First dialogue detected at ${firstDialogueTime.toFixed(1)}s: "${firstRealWord.text}"`);
          }
        }
        
        // ĞœĞµÑ€Ğ´Ğ¶Ğ¸Ğ¼ Ğ·Ğ°ÑÑ‚Ğ°Ğ²ĞºĞ¸ Ğ¸ Ñ‚Ğ¸Ñ‚Ñ€Ñ‹ Ğ² ĞĞ”Ğ˜Ğ Ğ¿Ğ»Ğ°Ğ½ (ĞºĞ°Ğº Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¼Ğ¾Ğ½Ñ‚Ğ°Ğ¶Ğ½Ğ¾Ğ¼ Ğ»Ğ¸ÑÑ‚Ğµ!)
        // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾-Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ†Ğ° Ğ·Ğ°ÑÑ‚Ğ°Ğ²ĞºĞ¸
        const mergedScenes = mergeCreditsScenes(detectedScenes, videoDuration, videoFPS, {
          skipCreditsMerging: false,
          firstDialogueTime,  // ğŸ¤ ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°
        });
        chunkProgress.mergedScenes = mergedScenes;
        
        // ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¾Ğ²
        const openingMerged = mergedScenes.filter(s => s.type === 'opening_credits').reduce((sum, s) => sum + s.originalScenesCount, 0);
        const closingMerged = mergedScenes.filter(s => s.type === 'closing_credits').reduce((sum, s) => sum + s.originalScenesCount, 0);
        const regularCount = mergedScenes.filter(s => s.type === 'regular').length;
        
        console.log(`   ğŸ“Š PySceneDetect raw: ${detectedScenes.length} scenes`);
        console.log(`   ğŸ“Š After credits merge: ${mergedScenes.length} plans`);
        console.log(`   ğŸ“Š Breakdown:`);
        console.log(`      - Opening credits: ${openingMerged} scenes â†’ 2 plans`);
        console.log(`      - Closing credits: ${closingMerged} scenes â†’ 1 plan`);
        console.log(`      - Regular scenes: ${regularCount} plans`);
        console.log(`   ğŸ“Š Expected ~1061 plans (real montage sheet)`);
        
      } else {
        console.warn(`   âš ï¸ PySceneDetect not available`);
      }
    } catch (e) {
      console.error(`   âŒ Scene detection failed:`, e);
    }
    
    chunkProgress.detectedScenes = detectedScenes;
    chunkProgress.videoFPS = videoFPS;
    
    // Save face clusters
    if (faceClusters.length > 0) {
      chunkProgress.faceClusters = faceClusters.map(cluster => ({
        clusterId: cluster.clusterId,
        appearances: cluster.appearances,
        firstSeen: cluster.firstSeen,
        lastSeen: cluster.lastSeen,
        characterName: cluster.characterName || null,
        centroid: cluster.centroid ? Array.from(cluster.centroid) : [],
        // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ faceTimestamps ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ (worker mode), Ğ¸Ğ½Ğ°Ñ‡Ğµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¸Ğ· faces
        faceTimestamps: cluster.faceTimestamps || cluster.faces?.map(f => f.timestamp) || [],
      }));
      chunkProgress.useFaceRecognition = true;
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 6: Split & Upload Chunks
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    console.log(`\nâœ‚ï¸  STEP 6: Splitting into ${chunks.length} chunks...`);
    
    const chunkFiles = await splitVideoIntoChunks(
      originalVideoPath,
      chunks.map(c => ({
        chunkIndex: c.chunkIndex,
        startTime: c.startTime,
        endTime: c.endTime,
      })),
      tempDir
    );
    
    tempFiles.push(...chunkFiles.map(c => c.localPath));
    
    // Upload chunks
    console.log(`\nâ˜ï¸  Uploading ${chunkFiles.length} chunks...`);
    
    const PARALLEL_UPLOADS = 2;
    const uploadChunk = async (chunkFile: { chunkIndex: number; localPath: string }) => {
      const chunkStoragePath = `${video.user_id}/chunks-v5/chunk_${chunkFile.chunkIndex}_${Date.now()}.mp4`;
      
      const stats = fs.statSync(chunkFile.localPath);
      const fileBuffer = fs.readFileSync(chunkFile.localPath);
      
      const { error: uploadError } = await supabase.storage
        .from('videos')
        .upload(chunkStoragePath, fileBuffer, {
          contentType: 'video/mp4',
          cacheControl: '3600',
        });
        
      if (uploadError) {
        throw new Error(`Upload failed for chunk ${chunkFile.chunkIndex}: ${uploadError.message}`);
      }
      
      const { data: { publicUrl } } = supabase.storage
        .from('videos')
        .getPublicUrl(chunkStoragePath);
      
      return { chunkIndex: chunkFile.chunkIndex, url: publicUrl };
    };
    
    // Upload in batches
    const uploadedChunks: Array<{ chunkIndex: number; url: string }> = [];
    for (let i = 0; i < chunkFiles.length; i += PARALLEL_UPLOADS) {
      const batch = chunkFiles.slice(i, i + PARALLEL_UPLOADS);
      const results = await Promise.all(batch.map(uploadChunk));
      uploadedChunks.push(...results);
      console.log(`   ğŸ“¤ Uploaded ${Math.min(i + PARALLEL_UPLOADS, chunkFiles.length)}/${chunkFiles.length}`);
    }
    
    // Update chunk progress with URLs
    for (const uploaded of uploadedChunks) {
      chunkProgress.chunks[uploaded.chunkIndex].storageUrl = uploaded.url;
      chunkProgress.chunks[uploaded.chunkIndex].status = 'ready';
    }
    
    // Save progress
    await supabase
      .from('videos')
      .update({ chunk_progress_json: chunkProgress })
      .eq('id', videoId);
    
    // Cleanup temp files
    cleanupTempFiles(tempFiles);
    
    const totalTime = ((Date.now() - startTime) / 1000).toFixed(1);
    
    console.log(`\n${'â•'.repeat(70)}`);
    console.log(`âœ… V5 BETA INIT COMPLETE`);
    console.log(`${'â•'.repeat(70)}`);
    console.log(`   Total time: ${totalTime}s`);
    console.log(`   Scenes: ${chunkProgress.mergedScenes?.length || detectedScenes.length}`);
    console.log(`   Faces: ${faceClusters.length}`);
    console.log(`   Speakerâ†’Character mappings: ${Object.keys(chunkProgress.speakerCharacterMap).length}`);
    console.log(`\nğŸš€ Ready for chunk processing (process-chunk-v5)`);
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STEP 7: Trigger chunk processing
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    console.log(`\nğŸ¯ STEP 7: Triggering chunk processing...`);
    
    // Fire and forget
    fetch(`${savedBaseUrl}/api/process-all-chunks-v5`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ videoId }),
    }).catch(err => console.error('Failed to trigger chunk processing:', err));
    
    return NextResponse.json({
      success: true,
      videoId,
      sheetId: sheet.id,
      totalChunks: chunks.length,
      totalScenes: chunkProgress.mergedScenes?.length || detectedScenes.length,
      architecture: 'improved',
      processingVersion: 'v5-beta',
      speakerMappings: Object.keys(chunkProgress.speakerCharacterMap).length,
      faceClusters: faceClusters.length,
      initTime: totalTime,
    });
    
  } catch (error) {
    console.error('âŒ V5 BETA init error:', error);
    
    cleanupTempFiles(tempFiles);
    
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Init processing failed' },
      { status: 500 }
    );
  }
}
