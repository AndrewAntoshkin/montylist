# üé≠ Face Recognition Implementation Plan

## –ü–æ–¥—Ö–æ–¥: Face Clustering + Speaker Binding

**–ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏—Ç—Ä—ã!** –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ:
1. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –ª–∏—Ü –≤ –≤–∏–¥–µ–æ
2. –ü—Ä–∏–≤—è–∑–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫ —Å–ø–∏–∫–µ—Ä–∞–º —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω–µ

---

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
npm install face-api.js canvas @tensorflow/tfjs-node
```

**–ú–æ–¥–µ–ª–∏ face-api.js** (—Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ):
- face_recognition_model
- face_landmark_68_model  
- tiny_face_detector_model

---

## –≠—Ç–∞–ø 1: Face Clustering (lib/face-clustering.ts)

```typescript
import * as faceapi from 'face-api.js';
import { Canvas, Image } from 'canvas';
import * as tf from '@tensorflow/tfjs-node';
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

// –ü–∞—Ç—á–∏–º faceapi –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å node-canvas
// @ts-ignore
faceapi.env.monkeyPatch({ Canvas, Image });

let modelsLoaded = false;

async function loadModels() {
  if (modelsLoaded) return;
  
  const modelPath = './node_modules/face-api.js/weights';
  await faceapi.nets.tinyFaceDetector.loadFromDisk(modelPath);
  await faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath);
  await faceapi.nets.faceRecognitionNet.loadFromDisk(modelPath);
  
  modelsLoaded = true;
  console.log('‚úÖ Face-api.js models loaded');
}

interface FaceInstance {
  descriptor: Float32Array;
  timestamp: number;
  confidence: number;
}

interface FaceCluster {
  clusterId: string;
  faces: FaceInstance[];
  centroid: Float32Array;
  appearances: number;
  firstSeen: number;
  lastSeen: number;
}

/**
 * –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥
 */
async function extractFrames(
  videoPath: string,
  interval: number = 5
): Promise<Array<{time: number, imagePath: string}>> {
  const duration = await getVideoDuration(videoPath);
  const frames = [];
  const outputDir = './temp/face-frames';
  
  // –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
  await fs.mkdir(outputDir, { recursive: true });
  
  for (let time = 0; time < duration; time += interval) {
    const outputPath = path.join(outputDir, `frame_${time}.jpg`);
    
    await execAsync(
      `ffmpeg -ss ${time} -i "${videoPath}" -frames:v 1 -q:v 2 "${outputPath}"`
    );
    
    frames.push({ time, imagePath: outputPath });
  }
  
  console.log(`üì∏ Extracted ${frames.length} frames`);
  return frames;
}

/**
 * –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –ª–∏—Ü–∞ –≤–æ –≤—Å–µ—Ö –∫–∞–¥—Ä–∞—Ö
 */
async function detectAllFaces(
  frames: Array<{time: number, imagePath: string}>
): Promise<FaceInstance[]> {
  await loadModels();
  
  const allFaces: FaceInstance[] = [];
  
  for (const frame of frames) {
    const image = await canvas.loadImage(frame.imagePath);
    
    const detections = await faceapi
      .detectAllFaces(image, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withFaceDescriptors();
    
    for (const detection of detections) {
      allFaces.push({
        descriptor: detection.descriptor,
        timestamp: frame.time,
        confidence: detection.detection.score,
      });
    }
  }
  
  console.log(`üé≠ Detected ${allFaces.length} face instances`);
  return allFaces;
}

/**
 * –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ª–∏—Ü: –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ
 */
function clusterFaces(
  faces: FaceInstance[],
  distanceThreshold: number = 0.5
): FaceCluster[] {
  const clusters: FaceCluster[] = [];
  
  for (const face of faces) {
    let assignedCluster: FaceCluster | null = null;
    let minDistance = Infinity;
    
    // –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –∫–ª–∞—Å—Ç–µ—Ä
    for (const cluster of clusters) {
      const distance = euclideanDistance(face.descriptor, cluster.centroid);
      
      if (distance < distanceThreshold && distance < minDistance) {
        assignedCluster = cluster;
        minDistance = distance;
      }
    }
    
    if (assignedCluster) {
      // –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–ª–∞—Å—Ç–µ—Ä
      assignedCluster.faces.push(face);
      assignedCluster.appearances++;
      assignedCluster.lastSeen = Math.max(assignedCluster.lastSeen, face.timestamp);
      // –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º centroid
      assignedCluster.centroid = calculateCentroid(
        assignedCluster.faces.map(f => f.descriptor)
      );
    } else {
      // –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –∫–ª–∞—Å—Ç–µ—Ä
      clusters.push({
        clusterId: `FACE_${clusters.length}`,
        faces: [face],
        centroid: face.descriptor,
        appearances: 1,
        firstSeen: face.timestamp,
        lastSeen: face.timestamp,
      });
    }
  }
  
  // –§–∏–ª—å—Ç—Ä—É–µ–º: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π (‚â•10 –ø–æ—è–≤–ª–µ–Ω–∏–π)
  return clusters
    .filter(c => c.appearances >= 10)
    .sort((a, b) => b.appearances - a.appearances); // –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
}

/**
 * –ü–æ–ª–Ω—ã–π pipeline
 */
export async function clusterFacesInVideo(
  videoPath: string
): Promise<FaceCluster[]> {
  console.log('\nüé≠ FACE CLUSTERING STARTED');
  
  const frames = await extractFrames(videoPath, 5); // –ö–∞–∂–¥—ã–µ 5 —Å–µ–∫
  const faces = await detectAllFaces(frames);
  const clusters = clusterFaces(faces, 0.5);
  
  console.log(`\nüé≠ FACE CLUSTERING COMPLETE:`);
  console.log(`   Total faces detected: ${faces.length}`);
  console.log(`   Unique characters: ${clusters.length}`);
  
  for (const cluster of clusters) {
    console.log(`   ${cluster.clusterId}: ${cluster.appearances} appearances (${cluster.firstSeen}s - ${cluster.lastSeen}s)`);
  }
  
  return clusters;
}
```

---

### **–®–∞–≥ 3: –°–≤—è–∑—ã–≤–∞–µ–º Face Clusters —Å Speakers**

```typescript
// lib/face-speaker-binding.ts

/**
 * –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã –ª–∏—Ü –∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º —á–µ—Ä–µ–∑ speaker mapping
 */
export function bindFacesToCharacters(
  faceClusters: FaceCluster[],
  diarizationWords: DiarizedWord[],
  speakerToCharacter: Map<string, string> // A ‚Üí –ì–ê–õ–ò–ù–ê (–∏–∑ pre-calibration)
): Map<string, string> {
  
  const faceToCharacter = new Map<string, string>();
  
  console.log('\nüîó BINDING FACES TO CHARACTERS...');
  
  for (const cluster of faceClusters) {
    const speakerVotes = new Map<string, number>();
    
    // –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è –ª–∏—Ü–∞
    for (const face of cluster.faces) {
      // –ù–∞—Ö–æ–¥–∏–º —Å–ª–æ–≤–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ ¬±2 —Å–µ–∫ –æ—Ç —ç—Ç–æ–≥–æ –∫–∞–¥—Ä–∞
      const wordsNearby = diarizationWords.filter(w => {
        const wordTime = w.start / 1000;
        return Math.abs(wordTime - face.timestamp) < 2.0;
      });
      
      // –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤
      for (const word of wordsNearby) {
        speakerVotes.set(
          word.speaker, 
          (speakerVotes.get(word.speaker) || 0) + 1
        );
      }
    }
    
    // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∞–Ω—Ç–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
    const topSpeaker = Array.from(speakerVotes.entries())
      .sort((a, b) => b[1] - a[1])[0];
    
    if (topSpeaker && topSpeaker[1] >= 20) {
      const speaker = topSpeaker[0];
      const character = speakerToCharacter.get(speaker);
      
      if (character) {
        faceToCharacter.set(cluster.clusterId, character);
        
        console.log(`   ${cluster.clusterId} (${cluster.appearances} appearances) ‚Üí ${character} (speaker ${speaker}, ${topSpeaker[1]} word matches)`);
      }
    }
  }
  
  console.log(`\n‚úÖ Bound ${faceToCharacter.size}/${faceClusters.length} face clusters to characters`);
  
  return faceToCharacter;
  // FACE_0 ‚Üí –ì–ê–õ–ò–ù–ê
  // FACE_1 ‚Üí –Æ–°–ï–§
  // FACE_2 ‚Üí –¢–û–ú–ê
}
```

---

### **–®–∞–≥ 4: –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤ –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω–µ**

```typescript
// –í app/api/process-chunk-v4/route.ts

// –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ AI response, –ø–µ—Ä–µ–¥ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–µ–π:

// –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã –¥–æ–±–∞–≤–ª—è–µ–º face hints
const scenesWithFaceHints = await Promise.all(
  sceneBoundaries.map(async (scene) => {
    // –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä –∏–∑ —á–∞–Ω–∫–∞
    const charactersInFrame = await identifyCharactersInScene(
      chunkVideoPath,
      `${scene.start_timecode} - ${scene.end_timecode}`,
      faceClusters,
      faceToCharacter
    );
    
    return {
      ...scene,
      charactersInFrame, // ["–ì–ê–õ–ò–ù–ê", "–Æ–°–ï–§"]
    };
  })
);

// –î–æ–±–∞–≤–ª—è–µ–º –≤ –ø—Ä–æ–º–ø—Ç:
const prompt = `
–°–æ–∑–¥–∞–π –º–æ–Ω—Ç–∞–∂–Ω—ã–π –ª–∏—Å—Ç –¥–ª—è ${scenes.length} –ø–ª–∞–Ω–æ–≤.

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–ª–∞–Ω–∞ –ò–ó–í–ï–°–¢–ù–û –∫—Ç–æ –≤ –∫–∞–¥—Ä–µ (Face Recognition):

${scenes.map((s, i) => `
${i + 1}. ${s.start_timecode} - ${s.end_timecode}
   ‚ö†Ô∏è –í –ö–ê–î–†–ï: ${s.charactersInFrame.join(', ') || '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}
`).join('\n')}

–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π!
...
`;
```

---

## üìä **–û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:**

### **–° Face Clustering + Speaker Binding:**

| –ú–µ—Ç—Ä–∏–∫–∞ | –¢–µ–∫—É—â–µ–µ | –ü–æ—Å–ª–µ Face Recognition | –£–ª—É—á—à–µ–Ω–∏–µ |
|---------|---------|----------------------|-----------|
| **–ü–µ—Ä—Å–æ–Ω–∞–∂–∏ (–≥–ª–∞–≤–Ω—ã–µ)** | 56% | **95-98%** | +39-42% |
| **–ü–µ—Ä—Å–æ–Ω–∞–∂–∏ (–∂—ë–Ω—ã –Æ—Å–µ—Ñ–∞)** | ~20% | **90-95%** | +70-75% |
| **–ü–µ—Ä—Å–æ–Ω–∞–∂–∏ (–≤—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–µ)** | ~40% | **85-90%** | +45-50% |
| **–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** | 65% | **93-96%** | +28-31% |

---

## üéØ **–ü–û–ß–ï–ú–£ –≠–¢–û –õ–£–ß–®–ï –ß–ï–ú "–ò–ó –¢–ò–¢–†–û–í":**

| –ü–æ–¥—Ö–æ–¥ | –¢–∏—Ç—Ä—ã | Face Clustering |
|--------|-------|-----------------|
| **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç —Ç–∏—Ç—Ä–æ–≤** | ‚ùå –î–∞ (–Ω–µ –≤—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ª–∏—Ü–∞) | ‚úÖ –ù–µ—Ç |
| **–í—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏** | ‚ùå –ú–æ–≥—É—Ç –Ω–µ –±—ã—Ç—å –≤ —Ç–∏—Ç—Ä–∞—Ö | ‚úÖ –í—Å–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è |
| **–¢–æ—á–Ω–æ—Å—Ç—å** | ~80% (–µ—Å–ª–∏ —Ç–∏—Ç—Ä—ã —Ö–æ—Ä–æ—à–∏–µ) | **95-98%** |
| **–†–∞–±–æ—Ç–∞ —Å –ø–æ—Ö–æ–∂–∏–º–∏ –ª–∏—Ü–∞–º–∏** | ‚ö†Ô∏è –û–¥–∏–Ω –∫–∞–¥—Ä = –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö | ‚úÖ –ö–ª–∞—Å—Ç–µ—Ä = –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö |
| **–°–∏–Ω–µ—Ä–≥–∏—è —Å–æ speakers** | ‚ùå –ù–µ—Ç —Å–≤—è–∑–∏ | ‚úÖ –î–∞ (–≥–æ–ª–æ—Å + –ª–∏—Ü–æ) |

---

## üíæ **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:** Face clustering –¥–µ–ª–∞–µ–º **1 —Ä–∞–∑** –ø—Ä–∏ init-processing:

```typescript
// –í init-processing-v4/route.ts

// –ü–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ:
console.log('üé≠ Starting face clustering...');
const faceClusters = await clusterFacesInVideo(originalVideoPath);

// –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î:
await supabase.from('videos').update({
  face_clusters_json: JSON.stringify(faceClusters)
}).eq('id', videoId);

// –í process-chunk-v4/route.ts –ø—Ä–æ—Å—Ç–æ —á–∏—Ç–∞–µ–º:
const faceClusters = JSON.parse(video.face_clusters_json);
```

**–í—Ä–µ–º—è:** +2-3 –º–∏–Ω—É—Ç—ã –∫ init (–æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ–≥–æ –≤–∏–¥–µ–æ)

---

## ‚è±Ô∏è **Timeline –≤–Ω–µ–¥—Ä–µ–Ω–∏—è**

| –≠—Ç–∞–ø | –ó–∞–¥–∞—á–∞ | –í—Ä–µ–º—è |
|------|--------|-------|
| 1 | –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å face-api.js + –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ | 10 –º–∏–Ω |
| 2 | –ù–∞–ø–∏—Å–∞—Ç—å face-clustering.ts | 30 –º–∏–Ω |
| 3 | –ù–∞–ø–∏—Å–∞—Ç—å face-speaker-binding.ts | 30 –º–∏–Ω |
| 4 | –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ init-processing-v4 | 30 –º–∏–Ω |
| 5 | –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ process-chunk-v4 | 30 –º–∏–Ω |
| 6 | –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –≤–∏–¥–µ–æ | 30 –º–∏–Ω |
| **–ò–¢–û–ì–û** | | **2.5-3 —á–∞—Å–∞** |

---

## üöÄ **–•–æ—Ç–∏—Ç–µ –Ω–∞—á–∞—Ç—å –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ?**

–Ø –º–æ–≥—É:
1. ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
2. ‚úÖ –ù–∞–ø–∏—Å–∞—Ç—å –≤–µ—Å—å –∫–æ–¥
3. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ pipeline
4. ‚úÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Ç–µ–∫—É—â–µ–º –≤–∏–¥–µ–æ

**–ù–∞—á–∏–Ω–∞–µ–º?**
